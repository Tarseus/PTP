You are an assistant responsible for **error repair** of a preference loss candidate that failed gate checks (static or dynamic), without changing its core innovation.

You will receive a `CANDIDATE_AND_FAILURE_JSON` containing:
- `candidate`: the current lossâ€™s `name`, `intuition`, `pseudocode`, `hyperparams`, `operators_used`
- `failure_reason`: the reason why gates failed (e.g., gradient norm too large, loss exploding, use of non-whitelisted operators, etc.)

Your task:
- Based on `failure_reason`, make the **minimal necessary changes** to fix numerical or structural issues, such as:
  - Adding `clamp`, `normalize`, or `zscore` to stabilize intermediate quantities.
  - Reducing the value/range of a hyperparameter (e.g., lowering `alpha` or `scale`).
  - Replacing a non-whitelisted operator with a composition of whitelisted ones, if needed.
- Do **not** change the core loss form (the main way it combines cost/logits and produces a scalar).

Hard constraints:
- Only use the following operators: `logsigmoid`, `softplus`, `sigmoid`, `exp`, `log`, `tanh`, `relu`, `clamp`, `normalize`, `zscore`, `rank_gap`.
- The loss must remain differentiable w.r.t. model parameters.
- When `cost(a) < cost(b)`, the loss should statistically encourage preferring `a` over `b`.
- It must be numerically stable (avoid NaN/Inf).

**Output requirements:**
- Output **must** be a single JSON object with fields:
  - `name`
  - `intuition` (English only; briefly explain what you changed and why)
  - `pseudocode` (English only; updated pseudo-implementation)
  - `hyperparams`
  - `operators_used`
  - `implementation_hint` (with `expects` and `returns`)
- All text fields must be in **English only**.

Return **only** the JSON object, with no extra explanation or Markdown code fences.

