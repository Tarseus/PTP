Task: Propose a new **preference loss** for learning from pairwise preferences in combinatorial optimization (e.g., TSP), in a *free-form* way.

You may freely design the loss structure and are **not** restricted to Bradley–Terry, logistic, DPO, etc. Only three hard constraints:
1. The loss must be differentiable w.r.t. model parameters (subgradients are allowed).
2. For the same instance, if cost(a) < cost(b), the loss should *statistically* encourage the model to prefer a over b (weak preference consistency).
3. It must be numerically stable: extreme Δcost or logits must not produce NaN/Inf.

Setting:
- You consider a pair of solutions (a, b) for the same instance.
- `cost(a)` and `cost(b)` are scalar objective values (lower is better).
- The model produces log probabilities `logp(a)` and `logp(b)`.
- You may use any differentiable tensor operations available in PyTorch (`torch`, `torch.nn.functional`). The following operators are particularly relevant and well-tested for this task (but not mandatory): `logsigmoid`, `softplus`, `sigmoid`, `exp`, `log`, `tanh`, `relu`, `clamp`, `normalize`, `zscore`, `rank_gap`.

The baseline preference loss used in our method is derived from an entropy-regularized RL objective and can be viewed as a Bradley–Terry / logistic-style loss on the log-probability difference `logp(a) - logp(b)` with a temperature parameter and a margin that depends on the cost gap. Your proposed loss should be **theoretically compatible** with this family, in the sense that:
- It can be interpreted as optimizing a probabilistic preference model where the probability that `a` is preferred over `b` is a monotone function of `logp(a) - logp(b)` and the cost difference.
- It preserves the correct *sign* of the learning signal: when `cost(a) < cost(b)`, the expected gradient pushes `logp(a) - logp(b)` upwards, and when `cost(a) > cost(b)` it pushes it downwards.
- Any margins, normalizations, or reweightings you introduce should be functions of cost differences (and optionally their normalized versions) rather than arbitrary labels.

Design a loss that combines costs and log-probability differences via scaling, margins, normalization, or other *stable* nonlinear transforms so that:
- If `cost(a) < cost(b)` and `logp(a) < logp(b)`, the loss tends to **increase** (pressure to raise `logp(a)`).
- If `cost(a) < cost(b)` and `logp(a) > logp(b)`, the loss tends to **decrease** (reward current preference).
- In extreme cases (very large cost differences or logit differences), the loss remains bounded and finite.

You may also be given a `GLOBAL_FEEDBACK_JSON` object with fields:
- `burn_in_objectives`: a list of baseline objectives (e.g., the original `po_loss`) and their metrics (`hf_like_score`, `validation_objective`, `generalization_penalty`).
- `recent_elites`: a small set of strong discovered losses, each with:
  - `name`, `operators_used`, `hyperparams`
  - metrics: `hf_like_score`, `validation_objective`, `generalization_penalty`, `pair_count`
- `recent_failures`: statistics about recent gate failures, including:
  - `by_code`: aggregated counts for error codes such as `E_OPERATOR_VIOLATION`, `E_GRAD_EXPLODE`, `E_LOSS_OUT_OF_RANGE`, `E_RUNTIME_NAN_LOSS`, etc.
  - `examples`: representative failing IRs and their `static_reason` / `dynamic_reason`.
- `diversity_summary`: common operator sets and hyperparameter key patterns seen so far (use to avoid near-duplicates when exploring).
- `suggested_mode`: one of `"explore"`, `"refine"`, or `"combine"`, indicating whether you should focus on:
  - **explore**: propose qualitatively new structures far from existing elites;
  - **refine**: make targeted improvements to common successful patterns;
  - **combine**: fuse complementary ideas from multiple strong losses.

Use this feedback to avoid repeated failure modes and bias your design toward losses that are likely to perform well under the same evaluation protocol.
In the `intuition` field, explicitly mention which mode you conceptually followed using a phrase like `Mode: explore` / `Mode: refine` / `Mode: combine`.

**Output requirements (IMPORTANT):**
- Output **must be a single JSON object**, with fields:
  - `name` (string, English)
  - `intuition` (string, English; short explanation of the idea)
  - `pseudocode` (string, English; high-level description of the idea; not executed)
  - `hyperparams` (JSON object of hyperparameters)
  - `operators_used` (array of operator names you conceptually rely on, e.g. `["logsigmoid", "tanh", "clamp"]`)
  - `theoretical_basis` (string, English; a short description of the main theoretical framework or principle behind this loss, such as "Bradley–Terry logistic preference model with cost-dependent margins", "maximum-entropy RL with KL-regularized advantage shaping", or "margin-based classification style hinge loss on log-probability differences")
  - `implementation_hint` (JSON object with `expects` and `returns`)
  - `code` (string containing valid Python source code for the loss function)
- For `implementation_hint`:
  - `expects` **must** be a JSON array of short input names **only**, and **must** be exactly: `["cost_a", "cost_b", "log_prob_w", "log_prob_l"]`.
    Do **not** write descriptions or full sentences here. Do **not** use a single string or an object.
  - `returns` **must** be exactly the string `"scalar"`.
- For `code`:
  - It **must** define a function with the exact signature:

    `def generated_loss(batch, model_output, extra):`

  - The function must:
    - Read tensors from `batch`:
      * `cost_a`, `cost_b` (shape [N])
      * `log_prob_w`, `log_prob_l` (shape [N])
      * optional `weight` (shape [N]) which may be None.
    - Optionally read hyperparameters from `hyperparams` and/or `extra` (e.g. `alpha`).
    - Use only PyTorch (`torch`), `torch.nn.functional as F`, and standard differentiable tensor operations; do **not** use non-numerical APIs such as file I/O, subprocesses, networking, or reflection.
    - Return a **scalar tensor** representing the mean loss over the batch.
  - Do **not** wrap the code in Markdown fences. Encode it as a normal JSON string with escaped newlines (`\n`).
- All text fields (including `intuition` and `pseudocode`) must be in **English only**.

Return **only** the JSON object, with no extra explanation or Markdown code fences, and use **English only** in all string fields.
