You are an assistant responsible for **conceptual crossover** between existing preference loss candidates (parents), and must produce a single **child** preference loss.

Goal:
- The child must clearly inherit at least two key design ideas from the parents.
- The child must also introduce 1–2 new **coupling ideas**, such as a new normalization, a new margin schedule, or a stability trick.
- The overall design must remain numerically stable and differentiable.

You are given `PARENTS_JSON`, where each element has:
- `name`
- `intuition`
- `pseudocode`
- `hyperparams`
- `operators_used`
- `code` (a Python implementation of the loss function)
- `theoretical_basis` (a short English description of the underlying theoretical framework, e.g. "Bradley–Terry logistic preference model", "maximum-entropy RL", "margin-based classification on log-probabilities")
- `metrics` (empirical metrics for that parent, including `hf_like_score`, `validation_objective`, `generalization_penalty`, `pair_count`).

You may also be given a `GLOBAL_FEEDBACK_JSON` object, which summarizes the search history:
- `burn_in_objectives`: baseline objectives (such as the original `po_loss`) and their metrics.
- `recent_elites`: a small set of top-performing discovered losses, each with operators, hyperparameters, metrics, and potentially different theoretical bases.
- `recent_failures`: aggregated gate failures with error codes like `E_OPERATOR_VIOLATION`, `E_GRAD_EXPLODE`, `E_LOSS_OUT_OF_RANGE`, `E_RUNTIME_NAN_LOSS`, etc., plus representative failing IRs.
- `suggested_mode`: one of `"explore"`, `"refine"`, or `"combine"` indicating whether you should prioritize:
  - **explore**: more radical new couplings and *possibly* a different theoretical basis than the parents;
  - **refine**: small numerical/stability improvements to patterns that already work well under a similar theoretical basis;
  - **combine**: hybridize complementary ideas—and possibly multiple theories—from several strong parents.

Based on these parents and the global feedback, design a new loss and describe, in English, in `intuition` and `pseudocode`:
- Which ideas are inherited from which parents.
- What new couplings or modifications you introduce.
- How the theoretical basis of the child relates to the parents (e.g., re-using the same Bradley–Terry-style theory, or switching to a different RL-inspired or margin-based theory).
Explicitly indicate in the `intuition` string which conceptual mode you chose (explore / refine / combine), for example by including `Mode: combine`.

Hard constraints:
- You may use any differentiable tensor operations available in PyTorch (`torch`, `torch.nn.functional`); the operators `logsigmoid`, `softplus`, `sigmoid`, `exp`, `log`, `tanh`, `relu`, `clamp`, `normalize`, `zscore`, and `rank_gap` are recommended but not mandatory.
- The loss must be differentiable w.r.t. model parameters.
- When `cost(a) < cost(b)`, the loss should statistically encourage preferring `a` over `b`.
- It must be numerically stable (avoid NaN/Inf).
- The child loss must remain **theoretically compatible** with a probabilistic preference model in which the probability that `a` is preferred over `b` is a monotone function of `logp(a) - logp(b)` and the cost gap, in the same spirit as Bradley–Terry / logistic-style objectives. Any new coupling you introduce (e.g., new margins or normalizations) must preserve the correct sign of the learning signal: when `cost(a) < cost(b)`, gradients should on average increase `logp(a) - logp(b)`.

**Output requirements:**
- Output **must** be a single JSON object with fields:
  - `name`
  - `intuition` (English only)
  - `pseudocode` (English only; high-level description, not executed)
  - `hyperparams`
  - `operators_used`
  - `theoretical_basis` (English only; a short description of the main theoretical framework you are using for the child)
  - `implementation_hint` (with `expects` and `returns`)
  - `code` (Python implementation of the child loss function)
- For `implementation_hint`:
  - `expects` **must** be a JSON array of short input names **only**, e.g. `["cost_a", "cost_b", "logp_a", "logp_b"]`.
    Do **not** write descriptions or full sentences here. Do **not** use a single string or an object.
  - `returns` **must** be exactly the string `"scalar"`.
- For `code`:
  - It **must** define a function with the exact signature:

    `def generated_loss(batch, model_output, extra):`

  - The function must:
    - Read tensors from `batch`:
      * `cost_a`, `cost_b` (shape [N])
      * `log_prob_w`, `log_prob_l` (shape [N])
      * optional `weight` (shape [N]) which may be None.
    - Optionally read hyperparameters from `hyperparams` and/or `extra`.
    - Use only PyTorch (`torch`), `torch.nn.functional as F`, and standard differentiable tensor operations; do **not** use non-numerical APIs such as file I/O, subprocesses, networking, or reflection.
    - Return a scalar tensor representing the mean loss over the batch.
  - Do **not** wrap the code in Markdown fences. Encode it as a normal JSON string with escaped newlines (`\\n`).
- All text fields must be in **English only**.

Return **only** the JSON object, with no extra explanation or Markdown code fences.
