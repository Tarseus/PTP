{"generation": 0, "index": 0, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed to dynamically adjust the learning signal based on the magnitude of the cost difference between two solutions. It combines the robustness of a hinge loss with a non-linear, adaptive margin. The core idea is that when the cost difference is small, the model should be more certain about its preference (requiring a larger logit difference) before the loss becomes zero. Conversely, when the cost difference is large and the preference is obvious, the model can be less certain and still incur no penalty. This is achieved by using a tanh-scaled rank gap of the costs as a dynamic margin. The `softplus` function is used as a smooth alternative to the standard hinge loss (max(0, x)), ensuring the loss is always non-negative and has a smooth gradient. A temperature parameter `tau` controls the overall sensitivity of the loss to logit differences.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, tau, scale):\n  # Determine the preferred (w) and dispreferred (l) solution based on cost\n  if cost_a < cost_b:\n    cost_w, cost_l = cost_a, cost_b\n    logp_w, logp_l = logp_a, logp_b\n  else:\n    cost_w, cost_l = cost_b, cost_a\n    logp_w, logp_l = logp_b, logp_a\n\n  # Calculate the difference in log probabilities\n  logit_diff = logp_w - logp_l\n\n  # Calculate the normalized rank gap of costs. rank_gap is robust to outliers.\n  # It returns a value in [-1, 1], representing the normalized difference.\n  cost_gap = rank_gap(cost_w, cost_l) # This will be < 0 since cost_w < cost_l\n\n  # Create an adaptive margin using tanh. The margin is larger for smaller cost differences.\n  # scale > 0. A larger scale makes the margin more sensitive to small cost gaps.\n  # The margin is in [0, 1].\n  adaptive_margin = tanh(-scale * cost_gap)\n\n  # The core loss calculation.\n  # We want logit_diff to be greater than the adaptive_margin.\n  # The loss is softplus(margin - logit_diff), which is a smooth version of max(0, margin - logit_diff).\n  # We divide by temperature `tau` to control the steepness of the loss.\n  loss = softplus(adaptive_margin - logit_diff / tau)\n\n  return loss", "hyperparams": {"tau": {"default": 1.0, "description": "Temperature parameter to scale the logit difference. Smaller values make the loss more sensitive to the logit difference, demanding a stronger preference signal from the model."}, "scale": {"default": 5.0, "description": "Scaling factor for the cost gap inside the tanh function. A larger value makes the adaptive margin more sensitive to small differences in cost, creating a steeper change in the required margin for slightly different cost gaps."}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_w: A batch of costs for the preferred solutions (lower cost).", "cost_l: A batch of costs for the dispreferred solutions (higher cost).", "logp_w: A batch of log probabilities for the preferred solutions.", "logp_l: A batch of log probabilities for the dispreferred solutions.", "tau: Scalar hyperparameter.", "scale: Scalar hyperparameter."], "returns": "A scalar representing the mean loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 0, "index": 1, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, inspired by hinge loss, introduces an adaptive margin that is proportional to the normalized cost difference between two solutions. The core idea is that when the better solution 'a' (cost(a) < cost(b)) already has a sufficiently higher log-probability than 'b', the loss should be zero, providing no gradient. The 'sufficiently higher' threshold (the margin) is not fixed; instead, it scales with how much better 'a' is than 'b'. A large cost difference demands a large log-probability gap to be considered 'correct', while a small cost difference only requires a small gap. This prevents the model from over-optimizing on pairs with tiny, potentially noisy cost differences, and forces it to focus on creating a significant preference for pairs with substantial quality gaps. The use of `tanh` on the logit difference and `clamp` on the cost gap ensures extreme values are squashed, guaranteeing numerical stability. The `softplus` function ensures the loss is non-negative and smooth.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, beta, tau, M):\n    # 1. Determine the winning (w) and losing (l) solution based on cost\n    if cost_a < cost_b:\n        cost_w, cost_l = cost_a, cost_b\n        logp_w, logp_l = logp_a, logp_b\n    else:\n        cost_w, cost_l = cost_b, cost_a\n        logp_w, logp_l = logp_b, logp_a\n\n    # 2. Calculate the normalized cost gap, representing the preference strength\n    # Use rank_gap for robustness against cost distribution shifts\n    cost_gap = rank_gap(cost_l, cost_w) # Should be positive\n    # Clamp the gap to a max value M to limit its influence\n    clamped_gap = clamp(cost_gap, 0, M)\n\n    # 3. Define the adaptive margin based on the clamped cost gap\n    # The margin is beta * clamped_gap, meaning a bigger cost difference demands a bigger logp difference\n    adaptive_margin = beta * clamped_gap\n\n    # 4. Calculate the log-probability difference, squashed by tanh for stability\n    # tanh scales the difference to the [-1, 1] range, preventing explosions\n    logit_diff = logp_w - logp_l\n    stable_logit_diff = tanh(logit_diff / tau)\n\n    # 5. Compute the core hinge-like term\n    # We want stable_logit_diff to be greater than the adaptive_margin.\n    # The loss is positive only if stable_logit_diff < adaptive_margin.\n    hinge_term = adaptive_margin - stable_logit_diff\n\n    # 6. Apply softplus to get a smooth, non-negative loss\n    # softplus(x) is a smooth approximation of relu(x)\n    loss = softplus(hinge_term)\n\n    return loss", "hyperparams": {"beta": 1.0, "tau": 2.0, "M": 5.0}, "operators_used": ["rank_gap", "clamp", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "scalar_loss"}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 0, "index": 2, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named Adaptive Margin Hinge Loss, is inspired by the hinge loss (or margin loss) commonly used in SVMs and ranking problems, but with two key innovations for stability and adaptivity in preference learning. The core idea is to penalize the model only when its preference contradicts the ground truth cost, and the magnitude of this violation exceeds an adaptive margin. The margin is not fixed; it scales with the normalized difference in costs (the rank gap). This means that for pairs with a very large cost difference, the model is pushed harder to respect the preference, while for pairs with similar costs, the penalty is softer. The use of `tanh` on the logit difference and `clamp` on the cost gap ensures that extreme input values do not cause numerical instability (NaN/Inf), satisfying the hard constraints.", "pseudocode": "1. For a batch of pairs (a, b), compute the cost for each solution: costs_a, costs_b.\n2. Compute the log probabilities from the model: logp_a, logp_b.\n3. Calculate the rank gap for the cost difference, normalized to a [0, 1] range: `cost_gap = rank_gap(costs_a, costs_b, mode='minmax')`. This represents the normalized magnitude of preference.\n4. Define an adaptive margin `m = alpha * cost_gap`. This margin is larger for pairs with a clearer cost difference.\n5. Calculate the logit difference: `logit_diff = logp_a - logp_b`.\n6. Apply a bounded, non-linear transformation to the logit difference for stability: `stable_logit_diff = beta * tanh(logit_diff / beta)`. This prevents extreme logit differences from dominating the loss.\n7. The core hinge loss logic: calculate the penalty `penalty = m - stable_logit_diff`.\n8. Apply a ReLU-like activation to only penalize incorrect preferences: `loss = relu(penalty)`.\n9. The final loss is the mean of\u635f\u5931 over the batch.", "hyperparams": {"alpha": {"default": 2.0, "description": "Scales the adaptive margin. A larger alpha creates a stronger push for the model to align with cost differences."}, "beta": {"default": 5.0, "description": "Controls the clipping range of the tanh function for logit differences. It acts as a soft clamp, ensuring values are roughly within [-beta, beta] to prevent gradient explosion."}}, "operators_used": ["rank_gap", "tanh", "relu"], "implementation_hint": {"expects": ["pair_costs_a", "pair_costs_b", "pair_logp_a", "pair_logp_b"], "returns": "A scalar tensor representing the mean loss for the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 0, "index": 3, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed for robust preference learning in combinatorial optimization. Its core idea is to combine the principles of a hinge loss with an adaptive margin that is sensitive to the magnitude of the cost difference between two solutions. The hinge loss structure (`relu`) provides a clear objective: no penalty is incurred if the model's preference (`logit_diff`) for the better solution already exceeds a certain margin. The key innovation lies in how this margin is determined. Instead of a fixed value, the margin is dynamically scaled by the normalized cost difference, calculated using `tanh`. Using `tanh` on the z-scored cost difference ensures that the margin is bounded (between 0 and `alpha`), preventing extreme cost differences from creating excessively large, unstable gradients. This makes the training process more stable. Specifically, when the cost difference is small, the required margin is also small, allowing the model to focus on clear-cut cases. As the cost difference becomes more significant, the margin increases, pushing the model more forcefully to recognize this strong preference. The `beta` hyperparameter controls the sensitivity of the margin to the cost difference. This adaptive approach makes the loss both robust to outliers and sensitive to the nuanced quality differences between solutions.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logit_a, logit_b, alpha, beta):\n    # Ensure cost_w is always the better (smaller) cost\n    if cost_a < cost_b:\n        cost_w, cost_l = cost_a, cost_b\n        logit_w, logit_l = logit_a, logit_b\n    else:\n        cost_w, cost_l = cost_b, cost_a\n        logit_w, logit_l = logit_b, logit_a\n\n    # Calculate the difference in log probabilities, we want logit_w to be higher\n    logit_diff = logit_w - logit_l\n\n    # Calculate the normalized cost difference using rank_gap and tanh for stability\n    # rank_gap ensures the difference is positive. The zscore part is assumed to happen at batch level.\n    # Here we use a simplified version for clarity.\n    cost_diff_normalized = tanh(beta * rank_gap(cost_l, cost_w)) \n\n    # The margin is adaptive: it's scaled by the normalized cost difference\n    # It's larger for pairs with a more significant cost gap.\n    adaptive_margin = alpha * cost_diff_normalized\n\n    # Hinge loss structure: penalize only if the logit difference is not in the desired direction\n    # or doesn't meet the adaptive margin.\n    # We want logit_diff > adaptive_margin. So, loss is incurred if adaptive_margin - logit_diff > 0.\n    loss = relu(adaptive_margin - logit_diff)\n\n    return loss", "hyperparams": {"alpha": 5.0, "beta": 0.1}, "operators_used": ["rank_gap", "tanh", "relu"], "implementation_hint": {"expects": ["pair_costs_w: A tensor of costs for the winning solutions in a batch.", "pair_costs_l: A tensor of costs for the losing solutions in a batch.", "pair_logits_w: A tensor of logits for the winning solutions.", "pair_logits_l: A tensor of logits for the losing solutions.", "Note: It's assumed that the input pairs (w, l) are already sorted such that cost(w) < cost(l)."], "returns": "scalar: The mean loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 0, "ir": {"name": "Sigmoid-Scaled Adaptive Margin Loss", "intuition": "This loss function aims to create a dynamic, cost-sensitive margin. The core idea is that the required 'win margin' for the better solution's log-probability should be proportional to the difference in solution costs. A larger cost difference demands a larger log-probability gap. We use `tanh` on the normalized cost difference to create a bounded, non-linear scaling factor between -1 and 1. This prevents extreme cost differences from causing an infinitely large loss. The final loss is calculated using `softplus`, which is a smooth and non-negative approximation of ReLU, providing stability and a clear gradient signal when the margin is not met. The sigmoid scaling on the log probability difference adds another layer of stability, squashing extreme logit differences into a predictable range, thus preventing the loss from exploding when the model is overly confident or unconfident.", "pseudocode": "1. For a batch of solution pairs, calculate the cost difference: delta_cost = cost_a - cost_b.\n2. Normalize the delta_cost across the batch using z-score normalization to handle varying cost scales. Let's call it normalized_delta_cost.\n3. Create a bounded, adaptive margin by applying the tanh function: adaptive_margin = alpha * tanh(normalized_delta_cost).\n4. Calculate the log probability difference: logp_diff = logp(a) - logp(b).\n5. Scale the log probability difference using a sigmoid function for stability: scaled_logp_diff = beta * sigmoid(logp_diff).\n6. The core of the loss is the difference between the adaptive margin and the scaled log-probability difference. The loss should be high if the better solution (e.g., cost_a < cost_b) has a lower log probability.\n7. Apply the softplus function to the result from step 6 to ensure the loss is always non-negative and smooth: loss = softplus(adaptive_margin - scaled_logp_diff).", "hyperparams": {"alpha": 5.0, "beta": 1.0}, "operators_used": ["zscore", "tanh", "sigmoid", "softplus"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logp_a", "pair_logp_b"], "returns": "A scalar loss value, typically the mean of the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 1, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed to address the challenges of preference learning in combinatorial optimization, especially when cost differences vary dramatically across different problem instances. The core idea is to create a dynamic, cost-sensitive margin that the model's preference (logit difference) must overcome. The hinge loss structure (ReLU) ensures that correctly ordered pairs with a sufficient confidence margin receive zero loss, allowing the model to focus on misordered or uncertain pairs. The margin itself is adaptive: it's proportional to the rank-based gap between the costs, normalized to a [-1, 1] range by `tanh`. This prevents extremely large cost differences from creating excessively large, unstable gradients. The `tanh` function acts as a robust 'soft clamp', ensuring numerical stability while still being sensitive to the magnitude of the cost difference. An additional fixed margin `m` is included to enforce a minimum separation even for small cost gaps, preventing indifference. The loss is asymmetric: it only penalizes the model when the better solution (lower cost) is not preferred enough.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, beta, m):\n  # Assume cost_a is the preferred (lower) cost\n  # Ensure cost_a <= cost_b, swap if necessary\n  if cost_a > cost_b:\n    cost_a, cost_b = cost_b, cost_a\n    logp_a, logp_b = logp_b, logp_a\n\n  # Calculate the difference in model's log-probabilities\n  # We want logp_a to be greater than logp_b\n  logit_diff = logp_a - logp_b\n\n  # Calculate a normalized, rank-based cost difference\n  # This value is sensitive to the magnitude of the cost gap but bounded in [-1, 1]\n  normalized_cost_gap = tanh(rank_gap(cost_a, cost_b))\n\n  # Define an adaptive margin. The margin is larger for larger cost differences.\n  # beta controls sensitivity to the cost gap, m is a minimum base margin.\n  adaptive_margin = m + beta * normalized_cost_gap\n\n  # The core hinge loss structure.\n  # Loss is incurred only if the logit difference is less than the adaptive margin.\n  # We want logit_diff > adaptive_margin, so we penalize `adaptive_margin - logit_diff` when it's positive.\n  loss = relu(adaptive_margin - logit_diff)\n\n  return loss", "hyperparams": {"beta": {"description": "A scaling factor that controls how sensitive the margin is to the cost difference. Higher beta means larger cost differences demand a much stronger preference from the model.", "default_value": 2.0}, "m": {"description": "A small, positive constant representing the minimum margin. This ensures that even for very similar costs, the model is still encouraged to prefer the better solution by at least a small amount.", "default_value": 0.1}}, "operators_used": ["rank_gap", "tanh", "relu"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "A single scalar value for the loss, which is always >= 0."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 2, "ir": {"name": "SigmoidRankWeightedHingeLoss", "intuition": "This loss function combines the ideas of a rank-weighted margin and a sigmoid-based hinge loss to create a stable and effective preference learning signal. The core idea is to make the required log probability margin between a better solution (a) and a worse solution (b) proportional to their cost difference. Instead of a hard hinge (like max(0, margin - x)), it uses a smooth, sigmoid-like activation (softplus) which has better gradient properties. The cost difference is transformed using a sigmoid function, which naturally maps any cost gap into a (0, 1) range, acting as a dynamic margin. This prevents extreme cost differences from creating excessively large loss values, ensuring numerical stability. The loss penalizes the model when the log probability of the better solution isn't sufficiently higher than the worse one, with 'sufficiently higher' being defined by the normalized cost gap.", "pseudocode": "def SigmoidRankWeightedHingeLoss(cost_a, cost_b, logp_a, logp_b, beta, tau):\n  # Ensure a is the better solution (lower cost)\n  if cost_a > cost_b:\n    cost_a, cost_b = cost_b, cost_a\n    logp_a, logp_b = logp_b, logp_a\n\n  # Calculate log probability difference. We want logp_a > logp_b.\n  logp_diff = logp_a - logp_b\n\n  # Calculate the normalized cost difference. rank_gap is 1 if cost_a < cost_b, 0 otherwise.\n  # Here we assume pre-swapped, so it's always 1.\n  cost_diff = cost_b - cost_a\n\n  # Map the cost difference to a dynamic margin in [0, 1] using a scaled sigmoid.\n  # This prevents extreme cost_diff from causing instability.\n  # The larger the cost difference, the closer the margin is to 1.\n  dynamic_margin = sigmoid(cost_diff / tau)\n\n  # The target is for logp_diff to be greater than the margin scaled by beta.\n  # We formulate this as a hinge-like loss using softplus for smoothness.\n  # The loss is softplus(beta * dynamic_margin - logp_diff).\n  # This is approximately 0 if logp_diff >> beta * margin, and grows linearly otherwise.\n  loss = softplus(beta * dynamic_margin - logp_diff)\n\n  return loss", "hyperparams": {"beta": {"value": 10.0, "description": "Scales the influence of the dynamic margin. A higher beta enforces a stricter preference separation for a given cost difference."}, "tau": {"value": 1.0, "description": "Temperature parameter for scaling the cost difference before the sigmoid. A smaller tau makes the sigmoid steeper, meaning the margin saturates to 1 more quickly even for small cost differences. Controls the sensitivity to cost gaps."}}, "operators_used": ["sigmoid", "softplus"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "scalar_loss: A non-negative scalar representing the loss for the pair."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 3, "ir": {"name": "AdaptiveMarginRankLoss", "intuition": "This loss function aims to dynamically adjust the preference margin based on the normalized rank difference of the solution costs. It uses a tanh activation on the log probability difference to prevent extreme gradients and ensure numerical stability. The core idea is that pairs with a larger cost difference should enforce a stronger preference signal (a larger margin), while pairs with similar costs should have a smaller, softer margin. This prevents the model from being overly penalized for minor preference violations on nearly-equivalent solutions and focuses its learning capacity on clearly distinguishable pairs. The `softplus` function ensures the loss is always non-negative and provides a smooth, convex penalty.", "pseudocode": "def AdaptiveMarginRankLoss(cost_a, cost_b, logp_a, logp_b, beta, tau):\n  # 1. Calculate the signed rank gap, normalized to [-1, 1]. This represents the ground truth preference direction and magnitude.\n  # The rank_gap operator is assumed to handle a batch of pairs and return a normalized value.\n  # For a single pair, it could be implemented as sign(cost_b - cost_a) if costs are distinct, or a more robust batch-ranking method.\n  # We'll represent the normalized rank gap as `preference_target`.\n  preference_target = rank_gap(cost_a, cost_b) # Expected to be in [-1, 1]\n\n  # 2. Calculate the model's predicted preference difference, bounded and scaled.\n  logit_diff = logp_a - logp_b\n  model_preference = tanh(logit_diff / tau)\n\n  # 3. The loss is the squared error between the target preference and the model's predicted preference.\n  # This is a form of soft hinge loss where the margin is adaptive.\n  # A simpler view: it's a softplus on the difference between the model's preference and the target preference signal.\n  # We want `logit_diff` to be positive when `cost_a < cost_b` (i.e., `preference_target` is positive).\n  # So the penalty should be on `preference_target - logit_diff`.\n  # Let's refine this to be more direct with softplus.\n  # The argument to softplus should be negative when the model agrees with the preference.\n  # Agreement: sign(logit_diff) == sign(cost_b - cost_a) == sign(preference_target).\n  # Disagreement: sign(logit_diff) != sign(preference_target).\n  # So, we penalize -preference_target * logit_diff.\n  # The `beta` scales the magnitude of the cost difference's influence.\n  loss_argument = -beta * preference_target * tanh(logit_diff / tau)\n  loss = softplus(loss_argument)\n\n  return loss", "hyperparams": {"beta": {"default": 5.0, "description": "A scaling factor that controls how strongly the cost difference (via rank_gap) influences the loss magnitude. Higher beta means larger cost differences create steeper loss gradients."}, "tau": {"default": 1.0, "description": "A temperature parameter for scaling the logit difference before the tanh function. A smaller tau makes the tanh transition sharper, approximating a sign function, while a larger tau makes it smoother and less sensitive to small logit differences."}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logp_a", "pair_logp_b"], "returns": "A scalar loss value, typically the mean over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 4, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed for stable preference learning in combinatorial optimization. Its core idea is to create a dynamic, cost-sensitive margin that the model's preference (logit difference) must overcome. The margin is not fixed; instead, it's determined by the normalized rank gap between the costs of two solutions. This 'adaptivity' means that when one solution is significantly better than another (large cost difference), the model is pushed much harder to prefer it. Conversely, for nearly-identical solutions, the push is gentle, preventing overfitting to noisy or insignificant preferences. The loss uses a 'hinge' or 'relu' structure, meaning that if the model's preference already satisfies the adaptive margin, the loss is zero, allowing the model to focus its capacity on more difficult preference pairs. To ensure numerical stability, the cost difference is normalized using a z-score over the batch, and the final loss is scaled by a tanh function. This bounds the gradient, preventing explosions from extreme logit differences while still providing a strong learning signal.", "pseudocode": "def adaptive_margin_hinge_loss(costs_a, costs_b, logits_a, logits_b, beta, tau):\n    # costs_a, costs_b, logits_a, logits_b are vectors for a batch of pairs\n\n    # 1. Calculate cost difference and logit difference for each pair\n    cost_diff = costs_a - costs_b  # Negative if a is better\n    logit_diff = logits_a - logits_b\n\n    # 2. Normalize the cost difference across the batch to get a stable scale\n    # zscore computes (x - mean(x)) / (std(x) + epsilon)\n    normalized_cost_diff = zscore(cost_diff)\n\n    # 3. Compute the adaptive margin. The margin is proportional to how much better a is than b.\n    # We use rank_gap(b, a) which is positive when cost(a) < cost(b).\n    # Normalization makes it robust to the scale of raw cost values.\n    # A sigmoid is applied to bound the margin between 0 and beta.\n    margin = beta * sigmoid(rank_gap(costs_b, costs_a))\n\n    # 4. Calculate the core hinge loss.\n    # We want logit_diff to be > margin when a is better (cost_diff < 0).\n    # This is equivalent to margin - logit_diff needing to be < 0.\n    # The relu(margin - logit_diff) penalizes violations.\n    # Note: rank_gap(b, a) handles the preference direction, so we use it directly.\n    hinge_violation = relu(margin - logit_diff)\n\n    # 5. Apply a bounded scaling factor for stability.\n    # tanh(x) is bounded between -1 and 1. This prevents extreme gradients.\n    # The scaling factor is based on the magnitude of the violation.\n    bounded_scaler = tanh(hinge_violation / tau)\n\n    # 6. Combine for the final loss. We use the scaler to modulate the violation.\n    # This creates a smooth but saturating loss.\n    final_loss = bounded_scaler * hinge_violation\n\n    # 7. Average over the batch\n    return mean(final_loss)", "hyperparams": {"beta": 5.0, "tau": 1.0}, "operators_used": ["rank_gap", "zscore", "sigmoid", "relu", "tanh"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logit_a", "pair_logit_b"], "returns": "scalar_loss"}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 5, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function is inspired by the hinge loss (or margin loss) commonly used in SVMs, but adapted for preference learning in combinatorial optimization. The core idea is to enforce a 'margin' between the log-probabilities of two solutions, where the size of this margin is dynamically scaled by the difference in their costs. A larger cost difference demands a larger probability gap, while a smaller cost difference requires a smaller one. The `tanh` function is used to squash the cost difference, preventing extreme cost gaps from creating excessively large, unstable targets. This creates a 'soft' adaptive margin. The `softplus` function ensures the loss is always non-negative and smooth, acting like a smoothed ReLU, which penalizes violations of the margin (i.e., when the 'worse' solution has a probability that is too high relative to the 'better' one). The final loss is asymmetric: it only penalizes the model if its preference contradicts the ground-truth cost ordering beyond the adaptive margin; otherwise, the loss is near zero.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, beta, margin):\n    # Assume cost_a is the cost of the preferred solution (winner), cost_b is the loser's.\n    # cost_a < cost_b\n    \n    # 1. Calculate the difference in log probabilities.\n    logp_diff = logp_b - logp_a  # We want this to be negative (i.e., logp_a > logp_b).\n    \n    # 2. Calculate the normalized cost difference. tanh squashes it to [-1, 1].\n    # This makes the margin adaptive and robust to extreme cost differences.\n    cost_gap = cost_b - cost_a\n    adaptive_margin = margin * tanh(beta * cost_gap)\n    \n    # 3. Formulate the hinge-like loss.\n    # We penalize if logp_b - logp_a > -adaptive_margin, \n    # which is equivalent to penalizing if logp_b - logp_a + adaptive_margin > 0.\n    # The softplus(x) = log(1 + exp(x)) is a smooth version of max(0, x).\n    loss = softplus(logp_diff + adaptive_margin)\n    \n    return loss", "hyperparams": {"beta": 0.1, "margin": 5.0}, "operators_used": ["tanh", "softplus"], "implementation_hint": {"expects": ["cost_winner: a tensor of costs for the preferred solutions in a batch.", "cost_loser: a tensor of costs for the less-preferred solutions.", "logp_winner: a tensor of log probabilities for the preferred solutions.", "logp_loser: a tensor of log probabilities for the less-preferred solutions."], "returns": "A scalar representing the mean loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 6, "ir": {"name": "Adaptive Margin Ranking Loss with Temperature Scaling", "intuition": "This loss function, named AM-RankT, is a novel variant of a margin-based ranking loss, specifically designed for combinatorial optimization preference learning. Its core idea is to create an 'adaptive margin' that is proportional to the normalized quality difference between two solutions. The intuition is that if one solution is vastly superior to another (large cost gap), the model should be penalized more heavily for preferring the worse one. Conversely, for solutions of similar quality, the penalty should be smaller, allowing the model more flexibility. A temperature parameter `tau` controls the sharpness of this adaptive margin, while a `beta` parameter scales the influence of the log probability difference. The `tanh` function is used to bound the influence of both the cost difference and the log probability difference, ensuring numerical stability against extreme values and preventing exploding gradients. The final `softplus` ensures the loss is always non-negative and smooth.", "pseudocode": "def am_rankt_loss(cost_a, cost_b, logp_a, logp_b, tau, beta, margin_scale):\n    # 1. Calculate the normalized cost difference. `rank_gap` provides a stable, normalized measure of quality difference.\n    # The output is in [-1, 1], where a positive value means a is better than b.\n    cost_diff_normalized = rank_gap(cost_b, cost_a)  # Swapped to align with preference: positive if cost_a < cost_b\n\n    # 2. Create an adaptive margin using tanh for stability. \n    # The margin is large when cost_a is much better than cost_b.\n    # `margin_scale` controls the maximum size of this margin.\n    adaptive_margin = margin_scale * tanh(cost_diff_normalized / tau)\n\n    # 3. Calculate the log probability difference.\n    logp_diff = logp_a - logp_b\n\n    # 4. Combine the log probability difference with the adaptive margin.\n    # The loss is incurred when the model's preference (logp_diff) doesn't align with the ground truth (adaptive_margin).\n    # `beta` scales the logp_diff, controlling how aggressively the model's probabilities are pushed.\n    # The negative sign ensures we penalize when a better solution has a lower log probability.\n    loss_argument = adaptive_margin - beta * logp_diff\n\n    # 5. Apply softplus to get a smooth, non-negative loss.\n    # softplus(x) = log(1 + exp(x)). It's a smooth approximation of ReLU.\n    loss = softplus(loss_argument)\n\n    return loss", "hyperparams": {"tau": {"default": 0.1, "description": "Temperature for scaling the cost difference. Smaller tau makes the adaptive margin sharper and more sensitive to small cost gaps."}, "beta": {"default": 1.0, "description": "Scaling factor for the log probability difference, similar to the beta in DPO. Controls the strength of the policy update."}, "margin_scale": {"default": 5.0, "description": "Maximum value for the adaptive margin. This bounds the target separation between log probabilities."}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar tensor representing the mean loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 7, "ir": {"name": "Sigmoid-Scaled Rank-Gap Loss", "intuition": "The core idea is to use the normalized rank gap of the costs as a dynamic, instance-aware margin. The magnitude of the cost difference between two solutions (a and b) should determine how strongly the model is penalized for preferring the worse solution. We use a sigmoid function to scale the logit difference, which prevents extreme logit values from causing instability. The final loss is a softplus function, which is a smooth approximation of ReLU, ensuring the loss is non-negative and encourages the logit difference to align with the cost difference.", "pseudocode": "1. Compute the cost difference: delta_cost = cost_b - cost_a. \n2. Normalize the cost difference using the rank_gap function to get a stable, scale-invariant measure of preference strength: cost_gap = rank_gap(cost_a, cost_b). This is positive if a is better than b. \n3. Compute the log-probability difference: logit_diff = logp_a - logp_b. \n4. The loss is calculated as softplus(-logit_diff * sigmoid(cost_gap * alpha)). The sigmoid term acts as a 'confidence' weight based on how significant the cost difference is. If cost_gap is large and positive (a is much better), sigmoid(cost_gap * alpha) approaches 1, and the loss becomes softplus(-logit_diff), strongly pushing logp_a to be greater than logp_b. If cost_gap is near zero, the sigmoid term is near 0.5, softening the penalty. If cost_gap is negative (a is worse), the sigmoid term is < 0.5, flipping the sign of the argument inside softplus, thus penalizing if logp_a > logp_b.", "hyperparams": {"alpha": {"default": 10.0, "description": "A scaling factor that controls the steepness of the sigmoid function applied to the cost gap. A higher alpha makes the loss more sensitive to small cost differences."}}, "operators_used": ["rank_gap", "sigmoid", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value, typically the mean of the loss over the batch of pairs."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 0, "ir": {"name": "SigmoidAttenuatedRankGapLoss", "intuition": "The core idea is to create a loss that is proportional to the rank gap between the costs of two solutions, but with two key modifications for stability and learning dynamics. First, the cost difference (\u0394_cost) is normalized using a rank-gap function, making it robust to the scale of the cost function. Second, the influence of this rank gap on the loss is modulated by how 'wrong' the model's current preference is. We use a sigmoid function on the log probability difference (\u0394_logp). When the model is confidently wrong (e.g., cost(a) < cost(b) but logp(a) << logp(b)), the sigmoid term approaches 1, applying the full 'rank_gap' penalty. When the model is already correct (logp(a) > logp(b)), the sigmoid term approaches 0, attenuating the loss and preventing the model from becoming overconfident on already-learned preferences. This creates a smooth, bounded, and adaptive loss signal that focuses learning on misranked pairs without being overly sensitive to extreme logit or cost differences.", "pseudocode": "def SigmoidAttenuatedRankGapLoss(cost_a, cost_b, logp_a, logp_b, alpha, margin):\n  # Determine the preferred (w) and dispreferred (l) solutions based on cost\n  if cost_a < cost_b:\n    cost_w, cost_l = cost_a, cost_b\n    logp_w, logp_l = logp_a, logp_b\n  else:\n    cost_w, cost_l = cost_b, cost_b\n    logp_w, logp_l = logp_b, logp_a\n\n  # Calculate the rank-based gap, normalized and non-negative\n  # rank_gap(c1, c2) is assumed to be a normalized difference, e.g., tanh(c2 - c1)\n  cost_gap = rank_gap(cost_w, cost_l)\n\n  # Calculate the difference in log probabilities, where a positive value is correct\n  logp_diff = logp_w - logp_l\n\n  # Calculate the attenuation factor. \n  # If logp_diff is very negative (model is wrong), sigmoid -> 1.\n  # If logp_diff is very positive (model is correct), sigmoid -> 0.\n  # The negative sign flips the logic to penalize incorrect preferences.\n  attenuation = sigmoid(-alpha * (logp_diff - margin))\n\n  # The loss is the product of the cost gap and the model's error signal (attenuation).\n  # This means the penalty is proportional to how significant the cost difference is,\n  # but only when the model is making a mistake.\n  loss = cost_gap * attenuation\n\n  return loss", "hyperparams": {"alpha": {"value": 1.0, "description": "Steepness of the sigmoid curve. Controls how sensitive the loss is to the log probability difference. Higher alpha means a sharper transition from penalty to no penalty."}, "margin": {"value": 0.0, "description": "A margin for the log probability difference. A positive margin encourages the model to prefer the better solution by at least this amount."}}, "operators_used": ["rank_gap", "sigmoid"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "A scalar loss value, typically the mean of the per-pair losses in the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 1, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "The core idea is to create a hinge-like loss where the 'margin' is not a fixed hyperparameter, but dynamically adapts based on the normalized cost difference between two solutions. A larger cost difference demands a larger log probability difference to satisfy the preference. The loss uses `tanh` to smoothly bound the influence of both cost differences and log probability differences, preventing explosions from extreme values. Specifically, the loss is `relu(m - logit_diff)`, where the margin `m` is `alpha * tanh(beta * cost_diff_normalized)`. This structure penalizes the model only when the preferred solution's log probability is not sufficiently higher than the dispreferred one, with 'sufficiently higher' being defined by the magnitude of their cost gap.", "pseudocode": "1. For a pair of solutions (a, b), get their costs cost_a, cost_b and model log probabilities logp_a, logp_b.\n2. Determine the winner (w) and loser (l) based on cost: if cost_a < cost_b, w=a, l=b, else w=b, l=a.\n3. Calculate the log probability difference: logit_diff = logp_w - logp_l.\n4. Calculate the normalized cost difference. This can be done using rank_gap or a simple scaled difference: cost_diff_norm = rank_gap(cost_l, cost_w). The rank_gap operator normalizes the difference to a range like [0, 1].\n5. Calculate the adaptive margin `m`: m = alpha * tanh(beta * cost_diff_norm). `alpha` controls the maximum margin, and `beta` controls how quickly the margin saturates with the cost difference.\n6. The final loss is a rectified linear unit (hinge loss) applied to the difference between the adaptive margin and the logit difference: loss = relu(m - logit_diff).", "hyperparams": {"alpha": {"default": 1.0, "description": "Scales the maximum possible margin. A larger alpha creates a stronger push for the model to separate probabilities."}, "beta": {"default": 5.0, "description": "Controls the steepness of the tanh function, determining how sensitive the margin is to small cost differences."}}, "operators_used": ["rank_gap", "tanh", "relu"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "scalar (the loss value for the pair, non-negative)"}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 2, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed for stable preference learning in combinatorial optimization. Its core idea is to create a dynamic, cost-sensitive margin that the model's preference (logit difference) must overcome. The margin is derived from the normalized rank gap of the costs, making it sensitive to the relative quality of the solutions but robust to the absolute scale of cost values. The loss uses a 'hinge-like' structure via `softplus`, penalizing the model only when its preference for the worse solution exceeds this adaptive margin. Specifically, it calculates `softplus(logit_diff_worse_better - margin)`. This means if the model already prefers the better solution sufficiently (i.e., `logit_diff_better_worse > margin`), the loss is near zero. If not, the loss increases, pushing the model to correct its preference. The use of `tanh` to scale the cost gap ensures the margin is always bounded (between 0 and `alpha`), preventing extreme cost differences from causing exploding gradients and ensuring numerical stability. This design elegantly combines cost-awareness and stability, focusing the training effort on 'difficult' pairs where the model's preference contradicts the ground truth cost.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logit_a, logit_b, alpha, beta):\n  # Determine which solution is better (w) and which is worse (l)\n  if cost_a < cost_b:\n    cost_w, cost_l = cost_a, cost_b\n    logit_w, logit_l = logit_a, logit_b\n  else:\n    cost_w, cost_l = cost_b, cost_a\n    logit_w, logit_l = logit_b, logit_a\n\n  # Calculate the logit difference, oriented as (worse - better)\n  # A positive value means the model incorrectly prefers the worse solution.\n  logit_diff = logit_l - logit_w\n\n  # Calculate a normalized, bounded cost difference to form the margin.\n  # rank_gap handles normalization against the batch's cost distribution.\n  # tanh ensures the result is bounded in [-1, 1], preventing explosion.\n  normalized_cost_gap = rank_gap(cost_l, cost_w) # Expected to be non-negative\n  bounded_gap = tanh(beta * normalized_cost_gap)\n\n  # The adaptive margin is scaled by alpha.\n  # It's larger for pairs with a more significant cost difference.\n  margin = alpha * bounded_gap\n\n  # Use softplus for a smooth hinge loss.\n  # Loss is incurred if logit_diff > margin, i.e., if the model's preference\n  # for the worse solution exceeds the deserved margin.\n  loss = softplus(logit_diff - margin)\n\n  return loss", "hyperparams": {"alpha": 1.0, "beta": 5.0}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logit_a", "pair_logit_b"], "returns": "scalar_loss"}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 3, "ir": {"name": "SigmoidAttenuatedMarginLoss", "intuition": "This loss function, named Sigmoid Attenuated Margin Loss (SAML), introduces a dynamic margin that adapts to the magnitude of the cost difference. The core idea is that when the cost difference between two solutions is large, the model should be more confident in its preference. We use a sigmoid function to scale the logit difference, which prevents extreme logit values from causing instability. The target margin itself is also scaled by a sigmoid function of the cost difference, creating a 'soft' target that saturates for very large cost differences. This prevents the loss from becoming excessively large when the ground truth preference is already very clear, focusing the learning on more subtle, hard-to-distinguish pairs. The overall structure is a softplus-based margin loss, which is smooth and avoids the 'zero gradient' issue of ReLU-based hinge losses for already-correct predictions, allowing for continuous preference strengthening.", "pseudocode": "def SAML_loss(cost_a, cost_b, logp_a, logp_b, beta, margin, tau):\n  # 1. Calculate cost and log probability differences\n  # cost_diff > 0 means b is worse than a\n  cost_diff = cost_b - cost_a\n  # logit_diff > 0 means model prefers a over b\n  logit_diff = logp_a - logp_b\n\n  # 2. Create a dynamic, bounded margin based on the cost difference\n  # The margin scales with cost_diff but saturates, controlled by 'margin'\n  dynamic_margin = margin * tanh(cost_diff / tau)\n\n  # 3. Attenuate the logit difference to prevent extreme values from dominating\n  # beta controls the steepness of the sigmoid, acting as an inverse temperature\n  attenuated_logit_diff = sigmoid(beta * logit_diff)\n  \n  # 4. Formulate the margin-based loss\n  # The loss is positive if the attenuated logit difference doesn't exceed the dynamic margin\n  # softplus(x) = log(1 + exp(x)), a smooth version of relu(x)\n  loss = softplus(dynamic_margin - attenuated_logit_diff)\n\n  return loss", "hyperparams": {"beta": 1.0, "margin": 2.0, "tau": 10.0}, "operators_used": ["tanh", "sigmoid", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value, typically the mean over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 4, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, inspired by hinge loss, introduces an adaptive margin that is proportional to the normalized cost difference between two solutions. The core idea is that when a better solution 'a' (cost(a) < cost(b)) is significantly better (large cost gap), the model should be more confident in preferring it, thus requiring a larger log probability difference (logit_diff). We use `tanh` to normalize the cost difference, preventing extreme cost gaps from creating excessively large margins and ensuring numerical stability. The `softplus` function is used as a smooth and non-negative version of the hinge loss (`relu`), ensuring the loss is always non-negative and has smooth gradients everywhere. This design directly links the magnitude of the cost improvement to the strength of the learning signal.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, alpha, beta):\n    # Calculate the difference in log probabilities\n    logit_diff = logp_a - logp_b\n\n    # Calculate the normalized cost difference using tanh for stability\n    # tanh maps any real number to [-1, 1]\n    cost_diff_normalized = tanh(beta * (cost_b - cost_a))\n\n    # Create an adaptive margin. If cost_a < cost_b, margin is positive.\n    # The margin's magnitude is proportional to the normalized cost difference.\n    adaptive_margin = alpha * cost_diff_normalized\n\n    # The loss is incurred if the logit_diff doesn't exceed the adaptive margin.\n    # We want logp_a > logp_b (logit_diff > 0) when cost_a < cost_b.\n    # The target is to have logit_diff >= adaptive_margin.\n    # Loss is calculated on `adaptive_margin - logit_diff`.\n    # softplus(x) = log(1 + exp(x)), a smooth version of relu(x).\n    loss = softplus(adaptive_margin - logit_diff)\n\n    return loss", "hyperparams": {"alpha": {"default": 5.0, "description": "Scales the adaptive margin. A higher alpha enforces a stronger separation for solutions with large cost differences."}, "beta": {"default": 0.1, "description": "Controls the sensitivity of the tanh normalization to the raw cost difference. A smaller beta makes the margin less sensitive to small cost changes."}}, "operators_used": ["tanh", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value (mean over the batch)."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 5, "ir": {"name": "AdaptiveMarginSoftplusLoss", "intuition": "This loss function is designed to be a soft, adaptive version of a hinge loss. The core idea is that the 'correct' margin between the log probabilities of two solutions should depend on how different their costs are. A large cost difference should demand a large log probability difference, while a small cost difference only requires a small one. We use `rank_gap` to get a robust, non-parametric measure of the cost difference, which is then scaled to form an adaptive margin. The `softplus` function is used instead of `relu` (as in a standard hinge loss) to provide a smooth, non-zero gradient everywhere, preventing the model from completely stopping learning when the preference is already correctly satisfied. A temperature parameter `tau` controls the sharpness of the loss curve, and a `clamp` on the rank gap prevents extreme cost differences from creating excessively large margins, ensuring numerical stability.", "pseudocode": "def AdaptiveMarginSoftplusLoss(cost_a, cost_b, logp_a, logp_b, tau, scale, max_gap):\n    # Preference direction: -1 if a is better, +1 if b is better\n    # We want logp_a > logp_b when cost_a < cost_b\n    # This is equivalent to logp_a - logp_b > 0\n    pref_direction = sign(cost_b - cost_a) # Should be -1 or +1\n    \n    # Calculate the difference in log probabilities\n    logp_diff = logp_a - logp_b\n    \n    # Calculate a robust, scaled, and capped measure of cost difference\n    # This will serve as our adaptive margin\n    raw_gap = rank_gap(cost_a, cost_b)\n    capped_gap = clamp(raw_gap, 0, max_gap)\n    margin = scale * capped_gap\n    \n    # The core of the loss: softplus(margin - pref_direction * logp_diff)\n    # If a is better (pref_direction = 1), we want logp_diff to be positive.\n    # The loss is softplus(margin - logp_diff). It's low if logp_diff > margin, high otherwise.\n    # If b is better (pref_direction = -1), we want logp_diff to be negative.\n    # The loss is softplus(margin + logp_diff). It's low if logp_diff < -margin, high otherwise.\n    # This can be unified.\n    \n    # The argument to softplus. We want this to be small.\n    # A smaller value means the model's preference aligns with the cost preference.\n    loss_argument = margin - pref_direction * logp_diff\n    \n    # Apply softplus with a temperature for smoothness control\n    # softplus(x) = log(1 + exp(x))\n    # We use softplus(x / tau) * tau for temperature scaling\n    scaled_loss_argument = loss_argument / tau\n    loss = softplus(scaled_loss_argument) * tau\n    \n    return loss", "hyperparams": {"tau": 1.0, "scale": 0.5, "max_gap": 10.0}, "operators_used": ["rank_gap", "clamp", "softplus"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logp_a", "pair_logp_b"], "returns": "scalar"}}, "static_ok": true, "static_reason": "", "dynamic_ok": false, "dynamic_reason": "backward_error: element 0 of tensors does not require grad and does not have a grad_fn", "loss_value": null, "grad_norm": null}
{"generation": 2, "index": 6, "ir": {"name": "SigmoidAttenuatedRankLoss", "intuition": "This loss function is designed to be a robust alternative to standard preference losses like DPO. The core idea is to create a 'target' preference strength based on the normalized cost difference, and then measure the deviation of the model's predicted preference strength from this target. The cost difference is transformed into a [-1, 1] range using a scaled tanh function, representing the 'ground truth' preference direction and magnitude. The model's log probability difference is also scaled. The loss is then a squared error between these two quantities, but critically, it is attenuated by a sigmoid function of the cost difference. This attenuation ensures that when the cost difference is negligible (i.e., the two solutions are of similar quality), the loss signal is very weak, preventing the model from overfitting to noisy or insignificant preferences. Conversely, when the cost difference is large and clear, the loss provides a strong gradient signal. This design directly addresses numerical stability and focuses the model's learning capacity on meaningful preferences.", "pseudocode": "def SigmoidAttenuatedRankLoss(cost_a, cost_b, logp_a, logp_b, alpha, beta, tau):\n  # 1. Calculate cost difference and model's preference score\n  cost_diff = cost_a - cost_b  # a is better if cost_diff < 0\n  logp_diff = logp_a - logp_b\n\n  # 2. Map cost difference to a target preference score in [-1, 1]\n  # tanh maps the scaled difference to a smooth target. A negative cost_diff (a is better) results in a positive target.\n  target_preference = -tanh(beta * cost_diff)\n\n  # 3. Calculate the model's predicted preference score, also scaled\n  model_preference = tanh(alpha * logp_diff)\n\n  # 4. Calculate the deviation between model and target\n  deviation = model_preference - target_preference\n\n  # 5. Create an attenuation factor based on the magnitude of the cost difference\n  # This factor is close to 0 for small |cost_diff| and approaches 1 for large |cost_diff|\n  # It determines how much we 'care' about this pair.\n  attenuation_weight = sigmoid(abs(cost_diff) / tau)\n\n  # 6. The final loss is the weighted squared error\n  # The weight ensures we penalize deviations more for pairs with significant cost differences.\n  loss = attenuation_weight * (deviation ** 2)\n\n  return loss", "hyperparams": {"alpha": {"default": 1.0, "description": "Scales the model's log probability difference before the tanh, controlling the saturation of the model's preference score."}, "beta": {"default": 5.0, "description": "Scales the cost difference before the tanh, controlling how sensitive the target preference is to cost variations."}, "tau": {"default": 0.1, "description": "Temperature parameter for the sigmoid attenuation. A smaller tau makes the attenuation sharper, focusing learning more on pairs with a cost difference greater than tau."}}, "operators_used": ["tanh", "sigmoid"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value, typically the mean over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 7, "ir": {"name": "SigmoidRankClippedMarginLoss", "intuition": "This loss function is designed to be robust and stable for combinatorial optimization preference learning. It combines three key ideas: (1) It uses the rank gap of costs, which is more stable than problemler-specific cost differences. (2) It introduces a dynamic, cost-dependent margin, encouraging the model to not just prefer the better solution, but to prefer it by an amount proportional to how much better it is. This is achieved by `alpha * tanh(beta * cost_diff)`. The `tanh` function clips the margin, preventing extremely large cost differences from dominating the gradient. (3) The entire term is passed through a `logsigmoid` function, which is a standard, numerically stable way to implement a logistic loss, ensuring the final loss is well-behaved and bounded, preventing NaN/Inf issues from extreme logit differences.", "pseudocode": "def SigmoidRankClippedMarginLoss(cost_a, cost_b, logp_a, logp_b, alpha, beta, tau):\n  # 1. Calculate cost difference and rank gap\n  cost_diff = rank_gap(cost_a, cost_b) # Normalized difference, e.g., (cost_b - cost_a) / (max(cost_a, cost_b) + epsilon)\n  \n  # 2. Calculate log probability difference (logits difference)\n  logit_diff = (logp_a - logp_b) / tau # tau is a temperature parameter\n  \n  # 3. Create a dynamic margin based on the cost difference, clipped by tanh\n  # This margin is larger for larger cost differences, but bounded.\n  dynamic_margin = alpha * tanh(beta * cost_diff)\n  \n  # 4. The core logic: we want logit_diff to be greater than the dynamic_margin.\n  # The loss penalizes when logit_diff < dynamic_margin.\n  # We formulate this as a logistic loss.\n  # The argument to logsigmoid is negative because we want to maximize (logit_diff - dynamic_margin).\n  loss = -logsigmoid(logit_diff - dynamic_margin)\n  \n  return loss", "hyperparams": {"alpha": {"description": "Maximum margin value. Controls the upper bound of the desired logit separation.", "default": 2.0}, "beta": {"description": "Scaling factor for the cost difference inside tanh. Controls how quickly the margin saturates.", "default": 1.0}, "tau": {"description": "Temperature for scaling the logit difference. Similar to DPO's beta.", "default": 1.0}}, "operators_used": ["rank_gap", "tanh", "logsigmoid"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logp_a", "pair_logp_b"], "returns": "A scalar loss value, typically the mean of the losses for all pairs in the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
