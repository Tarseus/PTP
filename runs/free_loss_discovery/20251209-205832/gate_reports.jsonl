{"generation": 0, "index": 0, "ir": {"name": "AdaptiveMarginRankLoss", "intuition": "This loss function, named Adaptive Margin Rank Loss (AMRL), is designed for stable and robust preference learning in combinatorial optimization. Its core idea is to dynamically adjust the 'margin' of preference based on the magnitude of the cost difference between two solutions. When the cost difference is large, the model is strongly penalized for getting the preference wrong. When the cost difference is small (i.e., the solutions are of similar quality), the loss becomes more lenient, preventing the model from over-optimizing on trivial differences and improving its generalization. It uses `tanh` to create a bounded, S-shaped scaling factor from the cost difference, which is then multiplied by the log-probability difference. This product represents a 'scaled preference violation'. The final `softplus` function ensures the loss is always non-negative and smooth, acting like a smoothed ReLU. This design avoids issues with extreme cost or logit values, ensuring numerical stability.", "pseudocode": "def amrl_loss(cost_a, cost_b, logp_a, logp_b, beta, margin_scale):\n    # 1. Calculate the difference in log probabilities (logits).\n    # This represents the model's current preference strength.\n    logit_diff = logp_a - logp_b\n\n    # 2. Calculate the rank-based cost difference.\n    # rank_gap(a, b) is 1 if a < b, -1 if a > b, 0 if a == b.\n    # This establishes the ground truth preference direction.\n    cost_rank = rank_gap(cost_a, cost_b) # returns -1, 0, or 1\n\n    # 3. Create an adaptive margin based on the magnitude of the cost difference.\n    # tanh squashes the scaled cost difference into a [-1, 1] range, creating a smooth, bounded scaling factor.\n    # This factor is large for large cost differences and small for small ones.\n    normalized_cost_diff = normalize(cost_b - cost_a) # Normalize to prevent extreme values\n    adaptive_margin = tanh(beta * normalized_cost_diff)\n    \n    # 4. Combine the model's preference with the adaptive margin.\n    # The goal is to make logit_diff have the same sign as adaptive_margin.\n    # We multiply by -1 because we want to minimize the loss. If signs match (correct preference),\n    # the product is positive, and after negation, we are minimizing a negative value (pushing it towards -inf).\n    # softplus(-x) is a smooth approximation of max(0, -x), which is the standard hinge loss form.\n    scaled_preference_violation = logit_diff * adaptive_margin\n\n    # 5. Apply a smooth, non-negative loss function (softplus).\n    # softplus(x) = log(1 + exp(x)).\n    # The loss is softplus(-scaled_preference_violation). This encourages scaled_preference_violation to be positive.\n    # Multiplying by margin_scale adjusts the overall loss magnitude.\n    loss = margin_scale * softplus(-scaled_preference_violation)\n\n    return loss", "hyperparams": {"beta": 5.0, "margin_scale": 1.0}, "operators_used": ["rank_gap", "normalize", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value (the mean loss over the batch)."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 0, "index": 1, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed for robust preference learning in combinatorial optimization. Its core idea is to create a dynamic, cost-sensitive margin that the model's preference (logit difference) must overcome. Unlike a fixed margin, this 'adaptive margin' is proportional to the normalized cost difference between two solutions. Specifically, it uses `tanh` to map the cost difference to a bounded range [-1, 1], preventing extreme cost gaps from dominating the loss signal. The final loss is calculated using a hinge-like structure (`relu`) which penalizes the model only when its preference for the better solution is not strong enough to clear this adaptive margin. This 'zero-loss region' encourages the model to be 'good enough' without demanding an arbitrarily large logit gap for well-separated solutions, promoting stability and preventing overfitting on easy pairs. The `softplus` function is used as a smooth, non-negative wrapper instead of the standard `relu` to ensure the loss is always differentiable, which is beneficial for gradient-based optimization.", "pseudocode": "def adaptive_margin_hinge_loss(cost_a, cost_b, logit_a, logit_b, beta, tau):\n  # Ensure cost_a is the better (lower) cost\n  if cost_a > cost_b:\n    cost_a, cost_b = cost_b, cost_a\n    logit_a, logit_b = logit_b, logit_a\n\n  # Logit difference reflecting preference for the better solution\n  logit_diff_win_vs_lose = logit_a - logit_b\n\n  # Calculate normalized cost difference. rank_gap is a safe way to get the sign.\n  # Here we use direct subtraction for clarity, assuming it's handled safely.\n  cost_diff = cost_b - cost_a\n\n  # Create an adaptive margin based on the cost difference.\n  # tanh scales the cost_diff to a bounded range [-1, 1], controlled by temperature tau.\n  # This prevents extreme cost differences from creating excessively large margins.\n  adaptive_margin = tanh(cost_diff / tau)\n\n  # The core hinge-like mechanism.\n  # We want logit_diff_win_vs_lose to be greater than the margin.\n  # The loss is incurred when beta * adaptive_margin > logit_diff_win_vs_lose.\n  # We use softplus for a smooth, non-negative, and always differentiable version of relu(x).\n  # softplus(x) is a smooth approximation of max(0, x).\n  loss_value = softplus(beta * adaptive_margin - logit_diff_win_vs_lose)\n\n  return loss_value", "hyperparams": {"beta": {"default": 1.0, "description": "A scaling factor for the adaptive margin, controlling how strongly the cost difference influences the required logit gap. Higher beta means cost differences have a larger impact."}, "tau": {"default": 1.0, "description": "A temperature parameter for normalizing the cost difference. It controls the sensitivity of the tanh function. A smaller tau makes the margin more switch-like (quickly saturates to 1), while a larger tau makes it more linear for a wider range of cost differences."}}, "operators_used": ["tanh", "softplus"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "A scalar loss value, typically the mean of the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 0, "index": 2, "ir": {"name": "AdaptiveSigmoidMarginLoss", "intuition": "This loss function, named Adaptive Sigmoid Margin Loss, is designed to dynamically adjust the preference margin based on the magnitude of the cost difference between two solutions. The core idea is to use the hyperbolic tangent (tanh) of the normalized cost difference as an adaptive margin. When the cost difference is small, the margin is also small, allowing the model to explore solutions with similar costs. As the cost difference becomes significant, the margin approaches a maximum value (defined by `beta`), creating a strong push for the model to clearly prefer the better solution. This `tanh` scaling ensures the margin is always bounded and smooth, preventing extreme cost differences from causing gradient explosions. The final loss is a logistic loss (softplus) applied to the difference between the logit difference and this adaptive margin, ensuring numerical stability and providing a well-behaved gradient for optimization.", "pseudocode": "def AdaptiveSigmoidMarginLoss(cost_a, cost_b, logit_a, logit_b, alpha, beta, tau):\n    # 1. Calculate the difference in log probabilities (logits).\n    logit_diff = logit_a - logit_b\n\n    # 2. Calculate the normalized cost difference. Lower cost is better.\n    # The rank_gap operator ensures a consistent sign (positive if a is worse, negative if a is better).\n    cost_diff_raw = rank_gap(cost_a, cost_b) # cost_a - cost_b\n\n    # 3. Create an adaptive, bounded margin using tanh.\n    # The margin scales with the cost difference but is bounded by [-beta, beta].\n    # tau controls the sensitivity of the margin to the cost difference.\n    adaptive_margin = beta * tanh(cost_diff_raw / tau)\n\n    # 4. Combine the logit difference and the adaptive margin.\n    # We want logit_a to be greater than logit_b if cost_a is less than cost_b.\n    # The target is for logit_diff to be greater than the (positive) margin.\n    # So we penalize -(logit_diff - adaptive_margin), which is adaptive_margin - logit_diff.\n    # The loss pushes logit_diff towards the adaptive_margin.\n    # alpha scales the overall magnitude of the loss.\n    scaled_value = alpha * (adaptive_margin - logit_diff)\n\n    # 5. Apply softplus for a smooth, non-negative, and stable loss value.\n    # softplus(x) = log(1 + exp(x)). This is a smooth version of ReLU.\n    loss = softplus(scaled_value)\n\n    return loss", "hyperparams": {"alpha": {"description": "A positive scaling factor for the overall loss magnitude. Controls the strength of the gradient.", "default": 1.0}, "beta": {"description": "A positive scaling factor that defines the maximum absolute value of the adaptive margin. It sets the target separation in logits for solutions with very different costs.", "default": 5.0}, "tau": {"description": "A positive temperature-like parameter that controls the steepness of the tanh function. A smaller tau makes the margin saturate more quickly with respect to the cost difference.", "default": 1.0}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logit_a", "logit_b"], "returns": "A scalar loss value, typically the mean of the loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 0, "index": 3, "ir": {"name": "SigmoidScaledRankGapLoss", "intuition": "This loss function aims to create a dynamic, cost-difference-aware margin. The core idea is that the required log-probability gap between a better solution (a) and a worse solution (b) should be proportional to their cost difference. We use a sigmoid function to scale the normalized cost difference (\u0394_cost), creating a 'target margin' that is always between 0 and 1. This prevents extreme cost differences from creating an infinitely large target margin, ensuring numerical stability. The loss is then a softplus-based hinge loss that pushes the log-probability difference (logp(a) - logp(b)) to exceed this dynamically calculated target margin. The softplus function ensures the loss is smooth and always non-negative.", "pseudocode": "def SigmoidScaledRankGapLoss(cost_a, cost_b, logp_a, logp_b, beta, tau):\n  # Assume cost_a < cost_b without loss of generality (preferred > dispreferred)\n  \n  # 1. Calculate normalized cost difference using rank_gap\n  # rank_gap(c1, c2) = (c2 - c1) / (abs(c1) + abs(c2) + epsilon), avoids division by zero\n  delta_cost_normalized = rank_gap(cost_a, cost_b)\n  \n  # 2. Create a dynamic, bounded target margin using a scaled sigmoid\n  # The margin is large when delta_cost is large, but capped near 1.0\n  target_margin = sigmoid(beta * delta_cost_normalized)\n  \n  # 3. Calculate the log probability difference\n  log_prob_diff = logp_a - logp_b\n  \n  # 4. Compute the loss using a softplus hinge-like structure.\n  # We want log_prob_diff to be greater than target_margin.\n  # The loss is high if (target_margin - log_prob_diff) is large and positive.\n  # The temperature 'tau' controls the smoothness of the softplus function.\n  loss = softplus(target_margin - log_prob_diff, temperature=tau)\n  \n  return loss", "hyperparams": {"beta": {"value": 10.0, "description": "Scales the normalized cost difference before the sigmoid. A higher beta makes the target margin more sensitive to small cost differences."}, "tau": {"value": 1.0, "description": "Temperature for the softplus function. A smaller tau makes the softplus function approximate the ReLU (hard margin) more closely, while a larger tau makes it smoother."}}, "operators_used": ["rank_gap", "sigmoid", "softplus"], "implementation_hint": {"expects": ["preferred_cost", "dispreferred_cost", "preferred_logp", "dispreferred_logp"], "returns": "A single scalar representing the loss for the pair."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 0, "ir": {"name": "SigmoidAttenuatedRankLoss", "intuition": "This loss function is designed to be robust to outliers in both cost differences and logit differences. The core idea is to create a 'target' preference strength based on the rank-normalized cost difference, and then measure the deviation from the model's current preference strength. The cost difference is transformed into a bounded target in [-1, 1] using `tanh`, making it insensitive to extreme cost gaps. The model's preference, represented by the logit difference, is also squashed using `tanh`. The final loss is a squared error between these two bounded values, but with a crucial addition: an attenuating factor based on the sigmoid of the logit difference. This sigmoid factor means that when the model is already very confident in the correct direction (e.g., logit_diff is very large and positive for a better solution), the loss becomes very small, effectively ignoring already 'solved' pairs. This focuses the training on difficult or incorrectly ranked pairs, improving efficiency and stability.", "pseudocode": "def SigmoidAttenuatedRankLoss(cost_a, cost_b, logp_a, logp_b, alpha, beta):\n    # 1. Calculate rank-normalized cost difference.\n    # rank_gap provides a stable, scale-invariant measure of cost difference.\n    cost_diff_normalized = rank_gap(cost_a, cost_b) # Should be > 0 if a is better\n\n    # 2. Transform normalized cost difference into a bounded target preference signal [-1, 1].\n    # tanh is used for its smooth, bounded nature, preventing extreme cost gaps from creating huge targets.\n    target_preference = tanh(alpha * cost_diff_normalized)\n\n    # 3. Calculate the log probability difference from the model.\n    logit_diff = logp_a - logp_b\n\n    # 4. Transform the model's logit difference into a bounded model preference signal [-1, 1].\n    model_preference = tanh(logit_diff)\n\n    # 5. Calculate the core squared error between target and model preference.\n    preference_error = (target_preference - model_preference)**2\n\n    # 6. Create an attenuating factor that reduces the loss for correctly and confidently ranked pairs.\n    # When logit_diff aligns with the cost difference (i.e., logit_diff > 0 for cost_a < cost_b),\n    # we want to reduce the loss as confidence grows.\n    # We use sigmoid(-beta * cost_diff_normalized * logit_diff). If signs match, the argument is negative, sigmoid -> 0.\n    # If signs mismatch, the argument is positive, sigmoid -> 1, applying full penalty.\n    attenuation_factor = sigmoid(-beta * cost_diff_normalized * logit_diff)\n\n    # 7. The final loss is the attenuated squared error.\n    loss = attenuation_factor * preference_error\n    return loss", "hyperparams": {"alpha": {"default": 1.0, "description": "Scales the normalized cost difference before tanh. Higher alpha makes the target preference more sensitive to small cost differences."}, "beta": {"default": 0.5, "description": "Controls the strength of the attenuation. Higher beta makes the loss decrease faster for correctly ranked pairs."}}, "operators_used": ["rank_gap", "tanh", "sigmoid"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value, typically the mean of the loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 1, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named Adaptive Margin Hinge Loss, is designed for robust preference learning in combinatorial optimization. Its core idea is to combine the principles of hinge loss with an adaptive margin that is sensitive to the magnitude of the cost difference. When the model's preference (logit difference) contradicts the ground truth cost preference, a penalty is applied. This penalty is not fixed; it scales with how 'wrong' the model is, but this scaling is controlled by a hyperbolic tangent (tanh) function. This prevents extreme cost differences from causing excessively large gradients, ensuring numerical stability. Specifically, the loss is zero if the model already prefers the better solution by a sufficient, cost-dependent margin. Otherwise, the loss increases, pushing the model to correct its preference. The use of `tanh` and `softplus` (a smooth version of ReLU) guarantees a smooth, non-exploding, and always non-negative loss landscape, making it suitable for gradient-based optimization.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, alpha, beta, tau):\n  # Determine the better (w) and worse (l) solutions based on cost\n  if cost_a < cost_b:\n    cost_w, cost_l = cost_a, cost_b\n    logp_w, logp_l = logp_a, logp_b\n  else:\n    cost_w, cost_l = cost_b, cost_a\n    logp_w, logp_l = logp_b, logp_a\n\n  # Calculate the difference in model's log-probabilities\n  logit_diff = logp_w - logp_l\n\n  # Calculate the normalized cost difference using rank_gap\n  # This represents the ground truth preference strength\n  cost_gap = rank_gap(cost_w, cost_l)\n\n  # Create an adaptive margin that grows with the cost gap but is bounded by tanh\n  # The margin is larger when the two solutions are clearly distinct in quality\n  adaptive_margin = alpha * tanh(cost_gap / tau)\n\n  # The core of the loss: a hinge-like structure.\n  # We want logit_diff to be greater than the adaptive_margin.\n  # The loss is incurred only if logit_diff < adaptive_margin.\n  # We use softplus for a smooth, non-negative loss.\n  # The term inside softplus is (adaptive_margin - logit_diff).\n  # beta scales the overall magnitude of the loss.\n  loss = beta * softplus(adaptive_margin - logit_diff)\n\n  return loss", "hyperparams": {"alpha": {"default": 1.0, "description": "Maximum margin value. Controls the upper bound of the desired separation between log-probabilities."}, "beta": {"default": 1.0, "description": "Overall scaling factor for the loss magnitude."}, "tau": {"default": 0.1, "description": "Temperature parameter for the tanh function. Controls the sensitivity of the adaptive margin to the cost gap. Smaller tau means the margin saturates more quickly."}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value, typically the mean of the loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 2, "ir": {"name": "SigmoidAttenuatedRankLoss", "intuition": "This loss function is designed to be robust to outliers in both cost differences and logit differences. It treats the preference learning problem as a regression-to-the-rank-gap task, but with a crucial twist: the influence of a sample is attenuated by how certain the model already is. The core idea is to compute a 'target' preference strength based on the normalized rank gap of the costs. This target is then compared to the model's current preference strength (logit difference). The loss is the squared error between the target and the model's output, but this error is weighted by a sigmoid function of the negative logit difference. When the model is already correctly confident (large positive logit_diff for a better solution), the weight becomes small, reducing the gradient and preventing overfitting to easy examples. Conversely, when the model is confidently wrong (large negative logit_diff), the weight approaches 1, focusing learning on significant errors. The use of `tanh` on the rank gap and `clamp` on the logit difference ensures that extreme input values do not lead to numerical instability.", "pseudocode": "def SigmoidAttenuatedRankLoss(cost_a, cost_b, logit_a, logit_b, beta, margin, tau):\n  # Ensure a is the better solution for consistent calculation\n  if cost_a > cost_b:\n    cost_a, cost_b = cost_b, cost_a\n    logit_a, logit_b = logit_b, logit_a\n\n  # Calculate the difference in model's log probabilities\n  logit_diff = logit_a - logit_b\n\n  # 1. Compute a normalized and bounded target preference from costs.\n  # rank_gap provides a normalized difference, tanh squashes it to [-1, 1].\n  # We expect cost_a < cost_b, so rank_gap is negative. We make it positive.\n  target_preference = -tanh(rank_gap(cost_a, cost_b))\n\n  # 2. Calculate the model's current preference strength, scaled and with a margin.\n  # The sigmoid maps the logit difference to a (0, 1) probability space.\n  # Scaling by beta controls the steepness.\n  model_preference = sigmoid(beta * (logit_diff - margin))\n\n  # 3. Calculate the error between target and model preference.\n  preference_error = target_preference - model_preference\n\n  # 4. Create an attenuation factor based on model's incorrectness.\n  # This factor is high when the model is wrong (logit_diff < 0) and low when correct (logit_diff > 0).\n  # Clamping prevents extreme logit_diff values from causing instability before the sigmoid.\n  # The temperature `tau` softens the transition.\n  attenuation_weight = sigmoid(-clamp(logit_diff, -10, 10) / tau)\n\n  # 5. The final loss is the attenuated squared error.\n  loss = attenuation_weight * (preference_error ** 2)\n\n  return loss", "hyperparams": {"beta": 1.0, "margin": 0.0, "tau": 0.5}, "operators_used": ["rank_gap", "tanh", "sigmoid", "clamp"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logit_a", "pair_logit_b"], "returns": "scalar_loss"}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 3, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named Adaptive Margin Hinge Loss (AMHL), combines the principles of a hinge loss with an adaptive margin. The core idea is to create a 'correctness' score that reflects how well the model's preference (logit difference) aligns with the ground-truth cost difference. The margin is not fixed; instead, it's a function of the normalized cost difference. When the cost difference is large, the model is required to show a correspondingly large logit difference to satisfy the preference. The loss is then a ReLU-activated (hinge) function of this margin-adjusted correctness score. This ensures that the loss is zero when the model's preference is 'correct enough' relative to the cost gap, and it penalizes incorrect preferences proportionally. Using tanh on the logit difference and a scaled sigmoid on the cost difference ensures all inputs to the core calculation are bounded, preventing numerical instability.", "pseudocode": "def amhl_loss(cost_a, cost_b, logit_a, logit_b, beta, margin_scale, tau):\n  # 1. Calculate logit difference and bound it to [-1, 1] for stability.\n  logit_diff = logit_a - logit_b\n  bounded_logit_diff = tanh(logit_diff / tau)\n\n  # 2. Calculate cost difference and normalize it to a preference signal in [-1, 1].\n  # A positive value means 'b' is preferred (cost_a < cost_b).\n  cost_diff_signal = rank_gap(cost_b, cost_a) # Returns 1 if a<b, -1 if a>b, 0 if a=b\n\n  # 3. Define an adaptive margin based on the magnitude of the cost difference.\n  # The margin is larger for more significant cost differences.\n  # sigmoid ensures the margin is bounded and smooth.\n  abs_cost_delta = abs(cost_a - cost_b)\n  adaptive_margin = margin_scale * sigmoid(abs_cost_delta)\n\n  # 4. The core of the loss: a hinge-like structure.\n  # We want the bounded_logit_diff to align with the cost_diff_signal.\n  # The term (cost_diff_signal * bounded_logit_diff) is a 'correctness' score, ideally close to +1.\n  # We penalize if this score is less than the required adaptive margin.\n  loss = relu(adaptive_margin - cost_diff_signal * bounded_logit_diff)\n\n  # 5. Apply a final scaling factor.\n  return beta * loss", "hyperparams": {"beta": {"value": 1.0, "description": "Overall scaling factor for the loss."}, "margin_scale": {"value": 0.5, "description": "Maximum value for the adaptive margin. Controls the required 'confidence' gap."}, "tau": {"value": 10.0, "description": "Temperature for scaling the logit difference before tanh. A larger tau makes the tanh transition sharper around zero."}}, "operators_used": ["rank_gap", "sigmoid", "tanh", "relu"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logit_a", "logit_b"], "returns": "A scalar loss value, typically the mean of the loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 4, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed for robust preference learning in combinatorial optimization. Its core idea is to combine the principles of a hinge loss with an adaptive margin that is sensitive to the magnitude of the cost difference. When the model's preference (logit difference) aligns with the true cost preference, the loss is zero. When they misalign, a penalty is applied. This penalty is not fixed; it scales with the 'rank gap' of the costs, meaning that larger errors in cost are penalized more heavily. To ensure numerical stability, the cost difference is normalized using a Z-score transformation over the batch, and the final loss is smoothed and bounded using the Softplus function. This prevents extreme cost or logit values from causing NaN/Inf gradients, satisfying all constraints while providing an intuitive and effective learning signal.", "pseudocode": "def adaptive_margin_hinge_loss(cost_a, cost_b, logit_a, logit_b, alpha, margin_scale):\n    # 1. Calculate the rank gap based on cost (lower is better)\n    # rank_gap > 0 if cost_a < cost_b, rank_gap < 0 if cost_a > cost_b\n    cost_diff = rank_gap(cost_a, cost_b)\n\n    # 2. Normalize the cost difference across the batch for stability\n    # This makes the margin adaptive to the current batch's cost distribution\n    normalized_cost_diff = zscore(cost_diff)\n\n    # 3. Define an adaptive margin that scales with the normalized cost difference\n    # The margin is larger for pairs with a more significant cost difference\n    adaptive_margin = margin_scale * abs(normalized_cost_diff)\n\n    # 4. Calculate the log probability difference\n    logit_diff = logit_a - logit_b\n\n    # 5. The core hinge-like mechanism\n    # We want logit_diff to be positive if cost_a < cost_b (i.e., cost_diff > 0)\n    # and negative if cost_a > cost_b (i.e., cost_diff < 0).\n    # This can be expressed as wanting sign(logit_diff) == sign(cost_diff).\n    # The term `logit_diff * normalized_cost_diff` should be positive.\n    # The loss is incurred when `logit_diff * normalized_cost_diff` is smaller than the margin.\n    # We use `-logit_diff * normalized_cost_diff` so that the loss is a hinge loss on `x` where `x` should be negative.\n    hinge_term = adaptive_margin - logit_diff * normalized_cost_diff\n\n    # 6. Apply a smooth, non-negative activation (ReLU-like) and scale\n    # softplus(x) is a smooth approximation of relu(x). This makes the loss non-negative.\n    # The final loss is non-zero only when the model's preference contradicts the cost-based preference\n    # by more than the adaptive margin.\n    loss = alpha * softplus(hinge_term)\n\n    return loss", "hyperparams": {"alpha": 1.0, "margin_scale": 0.5}, "operators_used": ["rank_gap", "zscore", "softplus"], "implementation_hint": {"expects": ["pair_costs_a", "pair_costs_b", "pair_logits_a", "pair_logits_b"], "returns": "A scalar loss value, averaged over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 5, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is designed for stable and effective preference learning in combinatorial optimization. Its core idea is to create a dynamic margin based on the normalized cost difference between two solutions. Unlike a fixed margin, this adaptive margin demands a larger log-probability gap when the cost difference is significant, and a smaller one when the costs are close. This prevents the model from over-optimizing on pairs with negligible cost differences while strongly enforcing preferences for pairs with substantial quality gaps. The loss uses a 'hinge' or 'relu' structure, meaning it only penalizes the model when its preference (logit difference) doesn't align with the ground-truth cost preference by a sufficient margin. To ensure numerical stability, the cost difference is first transformed into a rank-based gap and then normalized using a softplus-based function, which smoothly maps the gap to a [0, 1) range, preventing extreme values from causing exploding gradients. The final loss is a rectified linear unit on the margin minus the logit difference, ensuring the loss is always non-negative and zero when the model's preference is 'correct enough'.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, beta, tau):\n  # Determine the winning (w) and losing (l) solution based on cost\n  if cost_a < cost_b:\n    cost_w, cost_l = cost_a, cost_b\n    logp_w, logp_l = logp_a, logp_b\n  else:\n    cost_w, cost_l = cost_b, cost_a\n    logp_w, logp_l = logp_b, logp_a\n\n  # 1. Calculate a scaled, rank-based cost difference\n  cost_gap = rank_gap(cost_w, cost_l)\n\n  # 2. Normalize the cost gap into a [0, 1) range for stability and adaptivity\n  # softplus(x) = log(1 + exp(x)). This ensures the denominator is always > 1.\n  normalized_gap = cost_gap / (tau + softplus(cost_gap))\n\n  # 3. Define the adaptive margin, scaled by hyperparameter beta\n  margin = beta * normalized_gap\n\n  # 4. Calculate the log probability difference (logit difference)\n  logit_diff = logp_w - logp_l\n\n  # 5. Apply the hinge loss structure. Penalize only if logit_diff < margin.\n  loss = relu(margin - logit_diff)\n\n  return loss", "hyperparams": {"beta": {"value": 5.0, "description": "A scaling factor that controls the overall magnitude of the adaptive margin. A larger beta enforces a stronger preference."}, "tau": {"value": 1.0, "description": "A smoothing and stability parameter in the normalization step. It prevents division by a very small number when the cost gap is near zero, ensuring numerical stability."}}, "operators_used": ["rank_gap", "softplus", "relu"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "A scalar loss value, typically the mean of the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 6, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named 'Adaptive Margin Hinge Loss', is inspired by the hinge loss (max(0, m - y*f(x))) but with a dynamically adapting margin. The 'margin' is determined by the normalized cost difference between two solutions. A larger cost difference demands a larger log probability gap to satisfy the preference, thus creating a stronger push for the model to differentiate between significantly different solutions. The `tanh` function is used to scale the log probability difference into a bounded range [-1, 1], which prevents extreme logit values from causing instability. The `softplus` function ensures the final loss is non-negative and smooth, acting as a smoothed version of the ReLU (hinge) activation.", "pseudocode": "1. For a pair of solutions (a, b), calculate the cost difference: delta_cost = cost(b) - cost(a).\n2. Normalize the cost difference within a batch to get a stable scale, e.g., using z-score: normalized_delta_cost = zscore(delta_cost).\n3. Calculate the log probability difference: logit_diff = logp(a) - logp(b).\n4. Scale the logit difference into a bounded range using tanh: scaled_logit_diff = tanh(beta * logit_diff).\n5. Define the adaptive margin based on the normalized cost difference: margin = alpha * normalized_delta_cost.\n6. Compute the core hinge-like term: term = margin - scaled_logit_diff.\n7. Apply the softplus function to get a smooth, non-negative loss: loss = softplus(term). This is approximately log(1 + exp(term)).", "hyperparams": {"alpha": {"value": 1.0, "description": "Scales the adaptive margin derived from the cost difference. A larger alpha means cost differences have a stronger influence on the required logit gap."}, "beta": {"value": 0.5, "description": "Controls the sensitivity of the tanh function to the logit difference. A smaller beta makes the transition smoother, while a larger beta makes it sharper, approaching a sign function."}}, "operators_used": ["zscore", "tanh", "softplus"], "implementation_hint": {"expects": ["pair_costs_a", "pair_costs_b", "pair_logp_a", "pair_logp_b"], "returns": "A scalar representing the mean loss over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 1, "index": 7, "ir": {"name": "AdaptiveMarginSoftplusLoss", "intuition": "This loss function, designed for combinatorial optimization preference learning, introduces an 'adaptive margin' that dynamically adjusts based on the relative quality of two solutions. The core idea is to use a normalized cost difference (\u0394cost) to modulate the margin in a softplus-based loss. When the cost difference is large, the margin increases, creating a stronger push for the model to correctly order the solutions. When the difference is small, the margin shrinks, allowing the model more flexibility and preventing over-penalization for ambiguity. The use of tanh on the log probability difference and softplus for the final loss ensures numerical stability against extreme inputs, while the rank_gap operator provides a robust, scale-invariant measure of cost difference.", "pseudocode": "def AdaptiveMarginSoftplusLoss(cost_a, cost_b, logp_a, logp_b, beta, tau):\n    # 1. Calculate the rank-based normalized cost difference. It's in [-1, 1].\n    # rank_gap is 1 if a is better, -1 if b is better, 0 if equal.\n    norm_cost_diff = rank_gap(cost_a, cost_b)\n\n    # 2. Calculate the log probability difference.\n    logp_diff = logp_a - logp_b\n\n    # 3. Create an adaptive margin. The margin is `beta` when costs differ significantly, and shrinks to 0 when costs are similar.\n    # The magnitude of norm_cost_diff determines the margin size.\n    adaptive_margin = beta * norm_cost_diff\n\n    # 4. Stabilize the log probability difference using tanh.\n    # This bounds the influence of extreme logit differences, preventing explosions.\n    stable_logp_diff = tanh(logp_diff / tau)\n\n    # 5. Combine the terms. The goal is to make `stable_logp_diff` align with `adaptive_margin`.\n    # We want `stable_logp_diff` to be positive and large when `cost_a < cost_b` (i.e., `adaptive_margin > 0`).\n    # The loss is `softplus(-x)` where `x` is the alignment score.\n    # `x = adaptive_margin * stable_logp_diff` would be a simple choice, but let's use a margin-based form for clarity.\n    # We want `stable_logp_diff` to be greater than `adaptive_margin` (or at least have the same sign).\n    # Let's formulate it as pushing `stable_logp_diff` to be on the correct side of the margin.\n    # If cost_a < cost_b, norm_cost_diff=1, margin=beta. We want logp_diff > 0. Loss should be small if logp_diff is large and positive.\n    # The argument to softplus should be negative for low loss. So, we use `-(stable_logp_diff - adaptive_margin)` if we want `stable_logp_diff > adaptive_margin`.\n    # But we want to align signs, so let's use a simpler product form which is equivalent to DPO-style alignment.\n    # Let the argument be `-norm_cost_diff * stable_logp_diff * beta`. This is wrong, beta shouldn't scale the whole thing.\n    # Let's stick to the margin logic. We want to penalize `stable_logp_diff` for not matching the sign of `norm_cost_diff`.\n    # A good DPO-like argument is `beta * (logp_b - logp_a)` if a is preferred.\n    # Here, `a` is preferred if `norm_cost_diff` is 1. So the argument is `-beta * norm_cost_diff * logp_diff`.\n    # Let's use our stable version: `-beta * norm_cost_diff * stable_logp_diff`.\n    # This is equivalent to `softplus(-beta * tanh(logp_diff / tau))` when a is preferred.\n    # Let's try the margin formulation again, it's more intuitive.\n    # We want to minimize `softplus(margin - logp_diff)` for preferred `a`.\n    # Let's use the stabilized version: `softplus(adaptive_margin - stable_logp_diff)`.\n    # This doesn't work because when b is preferred, margin is negative, and we want logp_diff to be negative.\n    # The correct formulation is `softplus(-norm_cost_diff * stable_logp_diff * beta)` but this re-introduces beta as a global scale.\n\n    # Final refined pseudocode:\n    # The argument to softplus should capture the 'error'. Error is high if signs of logp_diff and cost_diff don't match.\n    # Let `x = norm_cost_diff * stable_logp_diff`. This value should be positive. We can use `softplus(-x)`.\n    # Let's add the margin `beta` as a scale to the cost signal.\n    argument = -beta * norm_cost_diff * stable_logp_diff\n    loss = softplus(argument)\n\n    return loss", "hyperparams": {"beta": 5.0, "tau": 1.0}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logp_a", "pair_logp_b"], "returns": "A scalar loss value, averaged over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 0, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function is inspired by the hinge loss (or margin loss) commonly used in SVMs, but with two key adaptations for preference learning in optimization. First, the 'margin' is not a fixed hyperparameter but is dynamically determined by the normalized difference in cost between two solutions. A larger cost difference demands a larger log probability difference to satisfy the preference, making the learning signal proportional to the 'obviousness' of the preference. Second, the hinge loss is 'softened' using the softplus function instead of a hard max(0, x). This ensures the loss is smooth everywhere, providing stable gradients even near the zero-hinge point. The tanh function is used to scale the log probability difference into a bounded range [-1, 1], preventing extreme logit differences from causing the loss to explode and improving numerical stability. This combination creates a loss that is both sensitive to the magnitude of preference and robust to outliers in model predictions or costs.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, beta, tau):\n    # 1. Normalize the cost difference to a scale of [0, 1]\n    # The rank_gap(b, a) is positive if cost(a) < cost(b)\n    normalized_cost_gap = rank_gap(cost_b, cost_a)\n\n    # 2. This gap becomes the dynamic margin the model must overcome\n    # A larger cost difference requires a larger log probability difference\n    dynamic_margin = normalized_cost_gap\n\n    # 3. Calculate the log probability difference\n    log_prob_diff = logp_a - logp_b\n\n    # 4. Scale the log_prob_diff to a bounded range [-tau, tau] using tanh\n    # This prevents extreme logits from dominating the loss and causing instability\n    scaled_log_prob_diff = tau * tanh(log_prob_diff / tau)\n\n    # 5. The core of the hinge loss: we want the scaled log probability difference\n    # to be greater than the dynamic margin. The loss is incurred when it's not.\n    # We use (margin - value) as the argument for the hinge.\n    hinge_argument = dynamic_margin - scaled_log_prob_diff\n\n    # 6. Apply a smooth hinge loss (softplus) scaled by a temperature `beta`.\n    # softplus(x) = log(1 + exp(x)). It's a smooth approximation of ReLU(x).\n    # Scaling by beta controls the steepness of the loss curve.\n    loss = softplus(beta * hinge_argument) / beta\n\n    return loss", "hyperparams": {"beta": {"default": 5.0, "description": "An inverse temperature parameter that controls the steepness of the softplus function. Higher beta makes it closer to a hard hinge loss (ReLU)."}, "tau": {"default": 10.0, "description": "A scaling and clamping factor for the log probability difference. It defines the effective range [-tau, tau] for the scaled difference, preventing extreme values."}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value, typically the mean over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 1, "ir": {"name": "NormalizedAsymmetricMarginLoss", "intuition": "This loss function is designed for stable preference learning in combinatorial optimization. It asymmetrically penalizes violations of the cost-based preference. The core idea is to create a 'margin' that the model's preference (logit difference) must overcome. This margin is not fixed; it's dynamically scaled by the normalized rank gap of the costs (`rank_gap(cost_a, cost_b)`), making the loss more sensitive to significant cost differences. The asymmetry is introduced by using `softplus` on the margin term: when the model correctly prefers the better solution (a), the loss is minimal, but when it incorrectly prefers the worse solution (b), the loss grows proportionally to how wrong it is. `tanh` is used to squash the logit difference, preventing extreme logit values from causing numerical instability and ensuring the loss is bounded. This design provides a stable, bounded, and cost-sensitive signal for training.", "pseudocode": "def NormalizedAsymmetricMarginLoss(cost_a, cost_b, logp_a, logp_b, tau, beta, margin):\n  # Assume cost_a < cost_b without loss of generality (preferred > dispreferred)\n  # If not, swap (a, b) and flip the sign of the final loss. The logic below assumes cost_a is the better cost.\n\n  # 1. Calculate the cost difference using a robust, rank-based metric.\n  # This is a placeholder; in a batch, it would be the normalized rank difference.\n  cost_diff_normalized = rank_gap(cost_a, cost_b)\n\n  # 2. Calculate the log probability (logit) difference.\n  logit_diff = logp_a - logp_b\n\n  # 3. Squash the logit difference to the range [-1, 1] for stability.\n  # The temperature 'tau' controls the steepness of the tanh function.\n  squashed_logit_diff = tanh(logit_diff / tau)\n\n  # 4. Create a dynamic, cost-sensitive margin.\n  # The margin is scaled by the normalized cost difference.\n  # 'beta' controls how much the cost difference influences the margin.\n  dynamic_margin = margin + beta * cost_diff_normalized\n\n  # 5. Combine squashed logits and the dynamic margin.\n  # The term will be positive if the model's preference is wrong (logit_diff < dynamic_margin).\n  loss_argument = dynamic_margin - squashed_logit_diff\n\n  # 6. Apply softplus for an asymmetric, smooth, non-negative loss.\n  # The loss is close to zero if the model's preference is correct and strong enough,\n  # and grows linearly for incorrect preferences.\n  loss = softplus(loss_argument)\n\n  return loss", "hyperparams": {"tau": {"value": 1.0, "description": "Temperature for scaling the logit difference before tanh. Higher tau makes the transition smoother. Controls sensitivity to logit differences."}, "beta": {"value": 2.0, "description": "Scaling factor for the normalized cost gap. Controls how much the cost difference influences the required preference margin."}, "margin": {"value": 0.1, "description": "A base, constant margin. Ensures a small penalty even for tiny cost differences, encouraging the model to distinguish between solutions."}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["pair_cost_a", "pair_cost_b", "pair_logp_a", "pair_logp_b"], "returns": "A scalar loss value, typically the mean of the loss over all pairs in the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 2, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function, named Adaptive Margin Hinge Loss, is designed for stable preference learning in combinatorial optimization. Its core idea is to combine a classic hinge loss structure with a dynamically adapting margin. The margin is determined by the normalized cost difference between two solutions, ensuring that pairs with larger quality gaps are pushed apart more forcefully by the model. The hinge loss (realized via `relu`) provides a clear objective: only penalize the model if its preference (`logit_diff`) doesn't align with the ground truth cost difference by at least the required margin. The `tanh` function is applied to the logit difference to squash it into a bounded range [-1, 1]. This prevents extreme logit values from causing instability or excessively large gradients, ensuring the loss remains numerically stable. The overall structure encourages the model to learn a preference ranking that is not only correct in direction but also proportional in magnitude to the true cost differences, while maintaining robustness.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logit_a, logit_b, beta, tau):\n    # 1. Calculate the rank-based cost difference.\n    # rank_gap provides a normalized, robust measure of cost difference.\n    cost_diff_rank = rank_gap(cost_a, cost_b) # Expected to be in [-1, 1]\n\n    # 2. Calculate the log probability difference.\n    logit_diff = logit_a - logit_b\n\n    # 3. Squash the logit difference to a bounded range for stability.\n    # This prevents extreme logit values from dominating the loss.\n    squashed_logit_diff = tanh(logit_diff / tau)\n\n    # 4. The core hinge loss mechanism with an adaptive margin.\n    # The margin is `cost_diff_rank`. The model is penalized if its\n    # squashed preference `squashed_logit_diff` doesn't 'beat' the cost difference.\n    # The loss is zero if the model's preference is already correct and strong enough.\n    # The sign is flipped (`cost_diff_rank - ...`) to align with the hinge loss formulation max(0, m - y*f(x)).\n    # Here, `cost_diff_rank` is the margin `m`, and `squashed_logit_diff` is the score `y*f(x)`.\n    loss = relu(cost_diff_rank - squashed_logit_diff)\n\n    # 5. Scale the final loss.\n    return beta * loss", "hyperparams": {"beta": {"value": 1.0, "description": "Overall scaling factor for the loss magnitude."}, "tau": {"value": 2.0, "description": "Temperature parameter for scaling the logit difference before the tanh squashing. A smaller tau makes the transition in tanh sharper, while a larger tau makes it smoother."}}, "operators_used": ["rank_gap", "tanh", "relu"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logit_a", "logit_b"], "returns": "A scalar loss value (after reduction, e.g., mean over the batch)."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 3, "ir": {"name": "Adaptive Margin Ranking Loss with Temperature Scaling (AM-RankT)", "intuition": "This loss function is inspired by margin-based ranking losses but introduces two key innovations for stability and adaptivity in combinatorial optimization. First, it uses a 'rank gap' instead of the raw cost difference, which is more robust to cost distributions with heavy tails or varying scales across different problem instances. Second, it employs a temperature-scaled tanh function to squash the log probability difference. This prevents extreme logit differences from dominating the gradient, ensuring numerical stability. The core idea is to create a dynamic margin based on the relative quality (rank gap) of the two solutions and enforce this margin on the model's preference (the squashed log probability difference). The softplus function ensures the loss is always non-negative and smooth.", "pseudocode": "def am_rankt_loss(cost_a, cost_b, logp_a, logp_b, tau, beta):\n    # Use rank_gap for a stable, scale-invariant measure of quality difference.\n    # The sign is flipped because lower cost is better.\n    quality_gap = rank_gap(cost_b, cost_a) # Positive if cost_a < cost_b\n\n    # Calculate the difference in log probabilities.\n    log_prob_diff = logp_a - logp_b\n\n    # Squash the log probability difference with a scaled tanh for stability.\n    # This bounds the influence of extreme logit differences.\n    squashed_log_prob_diff = tanh(log_prob_diff / tau)\n\n    # The core of the loss: we want the squashed log prob diff to be greater than the quality gap.\n    # The loss is incurred when squashed_log_prob_diff < beta * quality_gap.\n    # The expression is -(squashed_log_prob_diff - beta * quality_gap)\n    # or beta * quality_gap - squashed_log_prob_diff\n    margin_term = beta * quality_gap - squashed_log_prob_diff\n\n    # Use softplus to create a smooth, non-negative loss. It's like a smooth ReLU.\n    # loss = max(0, margin_term)\n    loss = softplus(margin_term)\n\n    return loss", "hyperparams": {"tau": {"description": "Temperature for scaling the log probability difference. A larger tau makes the tanh function's linear region wider, making the loss sensitive to smaller logit differences. A smaller tau squashes the difference more aggressively.", "default": 2.0}, "beta": {"description": "Scaling factor for the quality gap. It controls how much the cost difference (via rank_gap) influences the target margin.", "default": 1.0}}, "operators_used": ["rank_gap", "tanh", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A scalar loss value, typically the mean of the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 4, "ir": {"name": "AdaptiveMarginHingeLoss", "intuition": "This loss function creates a dynamic margin based on the normalized cost difference between two solutions. The intuition is that when one solution is significantly better than another (large cost gap), the model should be penalized more heavily for not preferring it, thus requiring a larger log probability gap to satisfy the preference. The `tanh` function is used to squash the log probability difference and the cost difference into a bounded range [-1, 1], preventing extreme values from causing numerical instability. The core idea is a hinge-like loss `max(0, margin - logit_diff)`, but the margin itself `tanh(alpha * normalized_cost_gap)` adapts to the quality difference of the pair, making the learning signal more informative.", "pseudocode": "def AdaptiveMarginHingeLoss(cost_a, cost_b, logp_a, logp_b, alpha, beta, tau):\n    # 1. Determine the preferred (w) and dispreferred (l) solution based on cost\n    if cost_a < cost_b:\n        cost_w, cost_l = cost_a, cost_b\n        logp_w, logp_l = logp_a, logp_b\n    else:\n        cost_w, cost_l = cost_b, cost_a\n        logp_w, logp_l = logp_b, logp_a\n\n    # 2. Calculate normalized cost gap and squash it into a bounded range\n    # rank_gap ensures non-negative difference, tau adds stability\n    cost_gap = rank_gap(cost_w, cost_l) # This will be >= 0\n    normalized_cost_gap = cost_gap / (cost_w + cost_l + tau)\n    \n    # 3. Define an adaptive margin based on the cost gap\n    # The margin is larger for pairs with a larger cost difference\n    adaptive_margin = tanh(alpha * normalized_cost_gap)\n    \n    # 4. Calculate the scaled log probability difference (logit preference)\n    # The model's current preference for the better solution\n    logit_preference = beta * (logp_w - logp_l)\n    \n    # 5. Compute the hinge loss with the adaptive margin\n    # The loss is the amount by which the model's preference falls short of the required margin\n    # We use relu(x) which is equivalent to max(0, x)\n    loss = relu(adaptive_margin - logit_preference)\n    \n    return loss", "hyperparams": {"alpha": {"value": 10.0, "description": "Controls the steepness of the adaptive margin. Higher alpha means the margin becomes sensitive to smaller cost differences."}, "beta": {"value": 1.0, "description": "Scaling factor for the log probability difference. Adjusts the relative importance of model logits vs. cost-derived margin."}, "tau": {"value": 1e-06, "description": "A small constant to prevent division by zero when normalizing the cost gap, ensuring numerical stability."}}, "operators_used": ["rank_gap", "tanh", "relu"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "A scalar loss value (the mean of the loss over the batch)."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 5, "ir": {"name": "Adaptive Margin Ranking Loss with Cost-based Temperature (AMR-CT Loss)", "intuition": "This loss function is a variation of the classic margin ranking loss, but with two key innovations for stability and adaptivity in combinatorial optimization. First, it uses a 'cost-based temperature' (\u03b2) to scale the logit difference. When the cost difference between two solutions is large, \u03b2 is small, meaning the model's current preference is trusted more, and the loss gradient is reduced. This prevents the model from being overly penalized for not perfectly ranking solutions with vastly different qualities, which is an easy task. Conversely, when costs are very close (a hard-to-distinguish pair), \u03b2 is large, amplifying the logit difference and forcing the model to learn finer-grained preferences. Second, it incorporates an 'adaptive margin' (m_adapt) that is proportional to the normalized cost difference. This means that for pairs with a large quality gap, the model is encouraged to produce a correspondingly large logit gap, while for similar-quality pairs, a smaller logit gap is acceptable. Both mechanisms are designed to be numerically stable by using tanh and clamping to bound extreme values, preventing gradient explosion from huge cost or logit differences.", "pseudocode": "def AMR_CT_Loss(cost_a, cost_b, logp_a, logp_b, tau, alpha, margin_scale):\n    # Assume cost_a is the better solution (cost_a < cost_b)\n    # For a batch, these costs should be normalized first (e.g., via zscore or rank_gap)\n    # Let's assume cost_a and cost_b are pre-normalized values in a reasonable range (e.g., [0, 1])\n\n    # 1. Calculate cost and log probability differences\n    cost_diff = cost_b - cost_a  # This will be > 0\n    logit_diff = logp_a - logp_b\n\n    # 2. Calculate Cost-based Temperature (\u03b2)\n    # tanh makes it stable. As cost_diff -> inf, beta -> 1/tau. As cost_diff -> 0, beta -> 0.\n    # We add 1 to the denominator to avoid division by zero and to have beta > 0.\n    # The scaling by alpha controls the sensitivity.\n    beta = (1 / tau) * tanh(cost_diff * alpha)\n\n    # 3. Calculate Adaptive Margin (m_adapt)\n    # The margin grows with the cost difference, but is capped by margin_scale.\n    m_adapt = margin_scale * tanh(cost_diff)\n\n    # 4. Combine into the core loss term\n    # We want logit_diff to be greater than the adaptive margin.\n    # The loss is incurred when logit_diff < m_adapt.\n    # The core term is (m_adapt - logit_diff).\n    # We scale this term by the cost-based temperature beta.\n    loss_argument = beta * (m_adapt - logit_diff)\n\n    # 5. Apply a smooth, non-negative activation function for the final loss\n    # softplus(x) = log(1 + exp(x)). It's a smooth version of ReLU.\n    # This ensures the loss is always non-negative and is zero when the preference is strongly correct.\n    loss = softplus(loss_argument)\n\n    return loss", "hyperparams": {"tau": 0.1, "alpha": 2.0, "margin_scale": 1.0}, "operators_used": ["tanh", "softplus"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "A single non-negative scalar loss value."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 6, "ir": {"name": "Sigmoid-Coupled Rank-Gap Loss", "intuition": "This loss function uses the rank gap of costs, scaled by a sigmoid function of the log-probability difference. The core idea is that the penalty for violating a preference should be proportional to how 'wrong' the model is (the log-probability difference), but this proportionality is smoothly capped by a sigmoid function. This prevents extreme logit differences from causing excessively large gradients, ensuring stability. Specifically, when the model strongly prefers the wrong solution (large negative logit_diff), the sigmoid approaches 0, making the loss a large positive value proportional to the rank_gap. When the model correctly prefers the better solution (large positive logit_diff), the sigmoid approaches 1, making the loss a small negative value, effectively rewarding the model. The softplus function ensures the final loss is non-negative and smooth.", "pseudocode": "def loss(cost_a, cost_b, logp_a, logp_b, beta, margin):\n  # cost_a is better than cost_b\n  # We want logp_a > logp_b\n  \n  # 1. Calculate the rank gap of costs. This normalizes the cost difference based on its magnitude.\n  # If cost_a < cost_b, rank_gap_val will be positive. We treat this as the target margin.\n  rank_gap_val = rank_gap(cost_a, cost_b)\n  \n  # 2. Calculate the difference in log probabilities.\n  logp_diff = logp_a - logp_b\n  \n  # 3. Compute a stable, bounded scaling factor from the logp_diff.\n  # sigmoid(beta * logp_diff) maps the difference to (0, 1).\n  # It represents how much the model's preference aligns with the ground truth.\n  # Value is ~1 if model strongly agrees, ~0 if it strongly disagrees, 0.5 if uncertain.\n  preference_alignment = sigmoid(beta * logp_diff)\n  \n  # 4. Combine rank_gap and alignment. We want to penalize misalignment.\n  # (1 - 2 * preference_alignment) maps the alignment score from (0, 1) to (-1, 1).\n  # -1 means strong agreement, +1 means strong disagreement.\n  # We multiply this by the rank_gap, so the penalty is proportional to the cost difference importance.\n  # We add a fixed margin to enforce a minimum separation.\n  raw_loss = (1 - 2 * preference_alignment) * rank_gap_val + margin\n  \n  # 5. Use softplus to ensure the loss is non-negative and smooth for gradient descent.\n  # softplus(x) = log(1 + exp(x)). It's a smooth version of ReLU.\n  final_loss = softplus(raw_loss)\n  \n  return final_loss", "hyperparams": {"beta": {"default": 1.0, "description": "Controls the steepness of the sigmoid function, adjusting sensitivity to log-probability differences."}, "margin": {"default": 0.1, "description": "A small positive constant to ensure a penalty even when the rank gap is zero but the preference is wrong."}}, "operators_used": ["rank_gap", "sigmoid", "softplus"], "implementation_hint": {"expects": ["cost_w", "cost_l", "logp_w", "logp_l"], "returns": "A scalar loss value, typically the mean over the batch."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
{"generation": 2, "index": 7, "ir": {"name": "SigmoidAttenuatedRankLoss", "intuition": "This loss function, named 'Sigmoid Attenuated Rank Loss', is designed for stable preference learning in combinatorial optimization. Its core idea is to create a 'target' preference strength based on the normalized cost difference and compare it with the model's predicted preference strength (logit difference). The cost difference is first transformed into a normalized rank gap, ensuring scale-invariance. This rank gap is then passed through a sigmoid function to create a bounded target preference score between -1 and 1. The difference between the model's logit difference and this target is then penalized using a softplus function, which acts like a smooth ReLU, ensuring the loss is always non-negative and has a smooth gradient. A key feature is the attenuation mechanism: when the model's preference already strongly aligns with a large cost difference (e.g., model strongly prefers the better solution), the loss approaches zero, preventing overconfident predictions from being excessively penalized and focusing the training on ambiguous or incorrect cases.", "pseudocode": "def SigmoidAttenuatedRankLoss(cost_a, cost_b, logp_a, logp_b, beta, margin):\n    # 1. Calculate the rank-based cost difference, normalized to [-1, 1].\n    # rank_gap(a, b) returns 1 if a < b, -1 if a > b, 0 if a == b.\n    cost_rank_gap = rank_gap(cost_a, cost_b)\n\n    # 2. Define the target preference strength using the cost rank gap.\n    # This creates a clear, bounded target: +1 for preferring 'a', -1 for preferring 'b'.\n    target_preference = cost_rank_gap\n\n    # 3. Calculate the model's predicted preference strength.\n    logit_diff = logp_a - logp_b\n\n    # 4. Calculate the core loss term. We want the sign of logit_diff to match the sign of target_preference.\n    # The term `-target_preference * logit_diff` is minimized when they have the same sign.\n    # This is analogous to the logistic loss term in DPO/Bradley-Terry.\n    # We scale it by beta to control the steepness of the loss.\n    # We add a margin to the loss argument, which requires the model's preference to be stronger than a certain threshold\n    # before the loss becomes negligible. The margin is only applied when the model is wrong.\n    # Let `x = -target_preference * logit_diff`. If x > 0 (wrong preference), we add margin.\n    # A simpler way is to add it to the target: `loss_argument = beta * (margin * target_preference - logit_diff)`\n    # Let's stick to a simpler formulation: `softplus(margin - target_preference * logit_diff)`\n    loss_argument = margin - target_preference * logit_diff\n\n    # 5. Apply softplus for a smooth, non-negative loss. \n    # The beta scaling controls how strongly we penalize deviations.\n    loss = softplus(beta * loss_argument)\n    \n    return loss", "hyperparams": {"beta": {"value": 1.0, "description": "Inverse temperature scaling factor. Higher values create a steeper loss, more aggressively penalizing preference mismatches."}, "margin": {"value": 0.0, "description": "A positive margin. The model is penalized until the logit difference in the correct direction exceeds this margin. A value of 0.0 makes it a pure logistic-style loss."}}, "operators_used": ["rank_gap", "softplus"], "implementation_hint": {"expects": ["cost_a", "cost_b", "logp_a", "logp_b"], "returns": "A single scalar loss value for the pair, which is differentiable."}}, "static_ok": false, "static_reason": "implementation_hint.returns must be 'scalar'."}
